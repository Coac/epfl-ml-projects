{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from features_engineering import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from group_by import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_y, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sub dataset \n",
    "- Group by numjet column (categorical data : (0, 1, 2, 3))\n",
    "- Group by the NaN columns\n",
    "\n",
    "We obtain at the end 8 datasets, one for each numjet and for each of these, 2 according to the NaN columns removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (227458, 30) (227458,) (227458,)\n",
      "1 (175338, 30) (175338,) (175338,)\n",
      "2 (114648, 30) (114648,) (114648,)\n",
      "3 (50794, 30) (50794,) (50794,)\n",
      "num_jet: 0\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (59263, 19) (59263, 1) (59263, 1)\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (168195, 20) (168195, 1) (168195, 1)\n",
      "\tRemove col : \n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (158095, 23) (158095, 1) (158095, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (17243, 22) (17243, 1) (17243, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (107905, 30) (107905, 1) (107905, 1)\n",
      "(0,) (6743, 29) (6743, 1) (6743, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (47555, 30) (47555, 1) (47555, 1)\n",
      "(0,) (3239, 29) (3239, 1) (3239, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "sub_jet_num_x_dict, sub_jet_num_y_dict, sub_jet_num_ids_dict = group_by_jetnum_NaN(submission_x, submission_y, submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (99913, 30) (99913,) (99913,)\n",
      "1 (77544, 30) (77544,) (77544,)\n",
      "2 (50379, 30) (50379,) (50379,)\n",
      "3 (22164, 30) (22164,) (22164,)\n",
      "num_jet: 0\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (73790, 20) (73790, 1) (73790, 1)\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (26123, 19) (26123, 1) (26123, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (69982, 23) (69982, 1) (69982, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (7562, 22) (7562, 1) (7562, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (47427, 30) (47427, 1) (47427, 1)\n",
      "(0,) (2952, 29) (2952, 1) (2952, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (20687, 30) (20687, 1) (20687, 1)\n",
      "(0,) (1477, 29) (1477, 1) (1477, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict = group_by_jetnum_NaN(x, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the best model for each of the sub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_false(x, y, w, predict_threshold):\n",
    "    \"\"\"Get the ratio of negative predictions over wrong predictions\"\"\"\n",
    "    \n",
    "    # Get the predicted values\n",
    "    pred_y = predict_labels(w, x, predict_threshold)\n",
    "    # Initialize at 0\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    \n",
    "    # If prediction is wrong, add 1, if prediction is wrong and negative, add 1\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "                \n",
    "    # Calculate which percentage of wrong predictions are due to negative value\n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    # Get the column number of the features that wil be removed\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    # Get the samples of the category numjet of PRI_num_jet and removed data\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x, numjet, index):\n",
    "    \"\"\"\n",
    "    Calculate different features depending on the data (category of PRI_num_jet and nan or not)\n",
    "    Which features are used has been done with trial and error to improve the loss\n",
    "    1. Normalize data\n",
    "    2. Build combinations\n",
    "    \"\"\"\n",
    "    if numjet == 0 and index == 0:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 6, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 7, 8)\n",
    "    elif numjet == 0 and index == 1:\n",
    "        x_numjet0_index1 = normalize(x)\n",
    "        polynomial_x = x_numjet0_index1\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.tanh(x_numjet0_index1)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x_numjet0_index1))), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x_numjet0_index1, 2)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x_numjet0_index1), 2)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x_numjet0_index1)), 2)), axis=1)\n",
    "    elif numjet == 1 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 2 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 2)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 3 and index == 0:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 5)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 6, 8)\n",
    "    elif numjet == 3 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "    else:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "def build_best_model(x_, y_, numjet, index):\n",
    "    \"\"\"\n",
    "    Build the best model with the best parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize k_fold and prediction threshold and build features\n",
    "    k = 5\n",
    "    predict_threshold = 0\n",
    "    polynomial_x = build_features(x_, numjet, index)\n",
    "\n",
    "    # Use the best lambda for best result\n",
    "    if numjet == 0 and index == 0:\n",
    "        lambda_ = 4.52035365636e-07\n",
    "    elif numjet == 0 and index == 1:\n",
    "        predict_threshold = -0.189898989899\n",
    "        lambda_ = 1e-06\n",
    "    elif numjet == 1 and index == 1:\n",
    "        lambda_ = 0.137382379588\n",
    "    elif numjet == 2 and index == 1:\n",
    "        lambda_ = 0.0188739182214\n",
    "    elif numjet == 3 and index == 0:\n",
    "        lambda_ = 7.27895384398e-05\n",
    "    elif numjet == 3 and index == 1:\n",
    "        predict_threshold = -0.1\n",
    "        lambda_ = 0.5\n",
    "    else:\n",
    "        lambda_ = 0.000001\n",
    "\n",
    "\n",
    "    #Gest the accuracy of test and train using k_fold_corss_validation\n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "    # Find optimal weights and loss with ridge regression\n",
    "    w, loss = ridge_regression(y_, polynomial_x, lambda_)\n",
    "\n",
    "    \n",
    "    print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "    \n",
    "    return w, predict_threshold, accuracy_train_k, accuracy_test_k\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-24 16:16:12.800330 combinations 2 : 0 / 28\n",
      "2017-10-24 16:16:14.826832 combinations 3 : 0 / 56\n",
      "2017-10-24 16:16:19.221915 combinations 3 : 50 / 56\n",
      "2017-10-24 16:16:19.829917 combinations 4 : 0 / 70\n",
      "2017-10-24 16:16:25.217727 combinations 4 : 50 / 70\n",
      "2017-10-24 16:16:27.650717 combinations 5 : 0 / 56\n",
      "2017-10-24 16:16:34.123693 combinations 5 : 50 / 56\n",
      "2017-10-24 16:16:34.972693 combinations 6 : 0 / 28\n",
      "2017-10-24 16:16:38.995732 combinations 7 : 0 / 8\n",
      "\t Predicted -1 but was 1 : 0.634313005143277\n",
      "0 0 Train Accuracy: 0.815689795365\n",
      "0 0 Test Accuracy: 0.814351538149\n",
      "2017-10-24 16:16:57.306693 combinations 2 : 0 / 28\n",
      "2017-10-24 16:16:59.425728 combinations 3 : 0 / 56\n",
      "2017-10-24 16:17:03.915726 combinations 3 : 50 / 56\n",
      "2017-10-24 16:17:04.530698 combinations 4 : 0 / 70\n",
      "2017-10-24 16:17:10.829698 combinations 4 : 50 / 70\n",
      "2017-10-24 16:17:13.437728 combinations 5 : 0 / 56\n",
      "2017-10-24 16:17:22.375663 combinations 5 : 50 / 56\n",
      "2017-10-24 16:17:23.389622 combinations 6 : 0 / 28\n",
      "2017-10-24 16:17:28.515669 combinations 7 : 0 / 8\n",
      "2017-10-24 16:17:32.329629 combinations 2 : 0 / 28\n",
      "2017-10-24 16:17:38.269344 combinations 3 : 0 / 56\n",
      "2017-10-24 16:17:50.026622 combinations 3 : 50 / 56\n",
      "2017-10-24 16:17:51.926363 combinations 4 : 0 / 70\n",
      "2017-10-24 16:18:05.718088 combinations 4 : 50 / 70\n",
      "2017-10-24 16:18:12.179396 combinations 5 : 0 / 56\n",
      "2017-10-24 16:18:31.018542 combinations 5 : 50 / 56\n",
      "2017-10-24 16:18:33.490543 combinations 6 : 0 / 28\n",
      "2017-10-24 16:18:46.492543 combinations 7 : 0 / 8\n",
      "\t Predicted -1 but was 1 : 0.8778979907264297\n",
      "0 1 Train Accuracy: 0.950612557427\n",
      "0 1 Test Accuracy: 0.949617151608\n",
      "2017-10-24 16:18:54.575700 combinations 2 : 0 / 45\n",
      "2017-10-24 16:18:58.793702 combinations 3 : 0 / 120\n",
      "2017-10-24 16:19:04.245665 combinations 3 : 50 / 120\n",
      "2017-10-24 16:19:11.982083 combinations 3 : 100 / 120\n",
      "2017-10-24 16:19:15.361114 combinations 4 : 0 / 210\n",
      "2017-10-24 16:19:23.636446 combinations 4 : 50 / 210\n",
      "2017-10-24 16:19:32.683906 combinations 4 : 100 / 210\n",
      "2017-10-24 16:19:41.934945 combinations 4 : 150 / 210\n",
      "2017-10-24 16:19:52.862901 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.5616155660377359\n",
      "1 0 Train Accuracy: 0.806441126036\n",
      "1 0 Test Accuracy: 0.802829379823\n",
      "2017-10-24 16:20:20.200244 combinations 2 : 0 / 45\n",
      "2017-10-24 16:20:24.473820 combinations 3 : 0 / 120\n",
      "2017-10-24 16:20:30.886153 combinations 3 : 50 / 120\n",
      "2017-10-24 16:20:38.097160 combinations 3 : 100 / 120\n",
      "2017-10-24 16:20:41.217189 combinations 4 : 0 / 210\n",
      "2017-10-24 16:20:49.303153 combinations 4 : 50 / 210\n",
      "2017-10-24 16:20:58.298158 combinations 4 : 100 / 210\n",
      "2017-10-24 16:21:07.147150 combinations 4 : 150 / 210\n",
      "2017-10-24 16:21:18.072709 combinations 4 : 200 / 210\n",
      "2017-10-24 16:21:23.702703 combinations 2 : 0 / 45\n",
      "2017-10-24 16:21:33.161874 combinations 3 : 0 / 120\n",
      "2017-10-24 16:21:44.908835 combinations 3 : 50 / 120\n",
      "2017-10-24 16:21:59.439834 combinations 3 : 100 / 120\n",
      "2017-10-24 16:22:05.489873 combinations 4 : 0 / 210\n",
      "2017-10-24 16:22:24.939018 combinations 4 : 50 / 210\n",
      "2017-10-24 16:22:48.695600 combinations 4 : 100 / 210\n",
      "2017-10-24 16:23:11.121599 combinations 4 : 150 / 210\n",
      "2017-10-24 16:23:34.422030 combinations 4 : 200 / 210\n",
      "2017-10-24 16:23:39.039186 combinations 2 : 0 / 45\n",
      "2017-10-24 16:23:39.606188 combinations 3 : 0 / 120\n",
      "2017-10-24 16:23:40.403191 combinations 3 : 50 / 120\n",
      "2017-10-24 16:23:41.346180 combinations 3 : 100 / 120\n",
      "2017-10-24 16:23:41.721246 combinations 4 : 0 / 210\n",
      "2017-10-24 16:23:42.664181 combinations 4 : 50 / 210\n",
      "2017-10-24 16:23:43.553185 combinations 4 : 100 / 210\n",
      "2017-10-24 16:23:44.692217 combinations 4 : 150 / 210\n",
      "2017-10-24 16:23:45.754224 combinations 4 : 200 / 210\n",
      "2017-10-24 16:23:45.992183 combinations 5 : 0 / 252\n",
      "2017-10-24 16:23:47.323192 combinations 5 : 50 / 252\n",
      "2017-10-24 16:23:48.771181 combinations 5 : 100 / 252\n",
      "2017-10-24 16:23:50.462220 combinations 5 : 150 / 252\n",
      "2017-10-24 16:23:52.444187 combinations 5 : 200 / 252\n",
      "2017-10-24 16:23:54.043184 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.9713740458015268\n",
      "1 1 Train Accuracy: 0.93167989418\n",
      "1 1 Test Accuracy: 0.921560846561\n",
      "2017-10-24 16:23:57.285185 combinations 2 : 0 / 45\n",
      "2017-10-24 16:23:57.693182 combinations 3 : 0 / 120\n",
      "2017-10-24 16:23:58.218219 combinations 3 : 50 / 120\n",
      "2017-10-24 16:23:58.863218 combinations 3 : 100 / 120\n",
      "2017-10-24 16:23:59.139222 combinations 4 : 0 / 210\n",
      "2017-10-24 16:23:59.909191 combinations 4 : 50 / 210\n",
      "2017-10-24 16:24:00.750181 combinations 4 : 100 / 210\n",
      "2017-10-24 16:24:01.742219 combinations 4 : 150 / 210\n",
      "2017-10-24 16:24:02.821218 combinations 4 : 200 / 210\n",
      "2017-10-24 16:24:03.034181 combinations 5 : 0 / 252\n",
      "2017-10-24 16:24:04.176181 combinations 5 : 50 / 252\n",
      "2017-10-24 16:24:05.416217 combinations 5 : 100 / 252\n",
      "2017-10-24 16:24:06.710217 combinations 5 : 150 / 252\n",
      "2017-10-24 16:24:08.173217 combinations 5 : 200 / 252\n",
      "2017-10-24 16:24:09.718219 combinations 5 : 250 / 252\n",
      "2017-10-24 16:24:10.150185 combinations 2 : 0 / 45\n",
      "2017-10-24 16:24:11.028202 combinations 3 : 0 / 120\n",
      "2017-10-24 16:24:12.198217 combinations 3 : 50 / 120\n",
      "2017-10-24 16:24:13.563217 combinations 3 : 100 / 120\n",
      "2017-10-24 16:24:14.163222 combinations 4 : 0 / 210\n",
      "2017-10-24 16:24:15.991180 combinations 4 : 50 / 210\n",
      "2017-10-24 16:24:17.946723 combinations 4 : 100 / 210\n",
      "2017-10-24 16:24:20.041223 combinations 4 : 150 / 210\n",
      "2017-10-24 16:24:22.339768 combinations 4 : 200 / 210\n",
      "2017-10-24 16:24:22.820807 combinations 5 : 0 / 252\n",
      "2017-10-24 16:24:25.343319 combinations 5 : 50 / 252\n",
      "2017-10-24 16:24:28.082771 combinations 5 : 100 / 252\n",
      "2017-10-24 16:24:31.065239 combinations 5 : 150 / 252\n",
      "2017-10-24 16:24:34.424463 combinations 5 : 200 / 252\n",
      "2017-10-24 16:24:38.782376 combinations 5 : 250 / 252\n",
      "2017-10-24 16:24:40.175377 combinations 2 : 0 / 45\n",
      "2017-10-24 16:24:44.202404 combinations 3 : 0 / 120\n",
      "2017-10-24 16:24:48.799375 combinations 3 : 50 / 120\n",
      "2017-10-24 16:24:53.761413 combinations 3 : 100 / 120\n",
      "2017-10-24 16:24:55.802406 combinations 4 : 0 / 210\n",
      "2017-10-24 16:25:01.666377 combinations 4 : 50 / 210\n",
      "2017-10-24 16:25:08.294753 combinations 4 : 100 / 210\n",
      "2017-10-24 16:25:15.622792 combinations 4 : 150 / 210\n",
      "2017-10-24 16:25:23.337908 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.4613196043896491\n",
      "2 0 Train Accuracy: 0.845118608329\n",
      "2 0 Test Accuracy: 0.839515023722\n",
      "2017-10-24 16:25:42.769781 combinations 2 : 0 / 45\n",
      "2017-10-24 16:25:46.405776 combinations 3 : 0 / 120\n",
      "2017-10-24 16:25:50.942272 combinations 3 : 50 / 120\n",
      "2017-10-24 16:25:56.917271 combinations 3 : 100 / 120\n",
      "2017-10-24 16:25:59.379307 combinations 4 : 0 / 210\n",
      "2017-10-24 16:26:05.700271 combinations 4 : 50 / 210\n",
      "2017-10-24 16:26:12.140274 combinations 4 : 100 / 210\n",
      "2017-10-24 16:26:19.361560 combinations 4 : 150 / 210\n",
      "2017-10-24 16:26:27.026160 combinations 4 : 200 / 210\n",
      "2017-10-24 16:26:31.138892 combinations 2 : 0 / 45\n",
      "2017-10-24 16:26:39.020905 combinations 3 : 0 / 120\n",
      "2017-10-24 16:26:48.819900 combinations 3 : 50 / 120\n",
      "2017-10-24 16:27:00.155907 combinations 3 : 100 / 120\n",
      "2017-10-24 16:27:05.387940 combinations 4 : 0 / 210\n",
      "2017-10-24 16:27:19.973635 combinations 4 : 50 / 210\n",
      "2017-10-24 16:27:35.410442 combinations 4 : 100 / 210\n",
      "2017-10-24 16:27:53.460442 combinations 4 : 150 / 210\n",
      "2017-10-24 16:28:11.422441 combinations 4 : 200 / 210\n",
      "2017-10-24 16:28:14.969434 combinations 2 : 0 / 45\n",
      "2017-10-24 16:28:15.103436 combinations 3 : 0 / 120\n",
      "2017-10-24 16:28:15.304439 combinations 3 : 50 / 120\n",
      "2017-10-24 16:28:15.536472 combinations 3 : 100 / 120\n",
      "2017-10-24 16:28:15.636471 combinations 4 : 0 / 210\n",
      "2017-10-24 16:28:15.921434 combinations 4 : 50 / 210\n",
      "2017-10-24 16:28:16.241471 combinations 4 : 100 / 210\n",
      "2017-10-24 16:28:16.609469 combinations 4 : 150 / 210\n",
      "2017-10-24 16:28:17.005471 combinations 4 : 200 / 210\n",
      "2017-10-24 16:28:17.090473 combinations 5 : 0 / 252\n",
      "2017-10-24 16:28:17.532470 combinations 5 : 50 / 252\n",
      "2017-10-24 16:28:18.008433 combinations 5 : 100 / 252\n",
      "2017-10-24 16:28:18.514433 combinations 5 : 150 / 252\n",
      "2017-10-24 16:28:19.068436 combinations 5 : 200 / 252\n",
      "2017-10-24 16:28:19.656469 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.8285714285714286\n",
      "2 1 Train Accuracy: 0.942542372881\n",
      "2 1 Test Accuracy: 0.902033898305\n",
      "2017-10-24 16:28:21.183433 combinations 2 : 0 / 45\n",
      "2017-10-24 16:28:21.352433 combinations 3 : 0 / 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-24 16:28:21.554472 combinations 3 : 50 / 120\n",
      "2017-10-24 16:28:21.789473 combinations 3 : 100 / 120\n",
      "2017-10-24 16:28:21.893437 combinations 4 : 0 / 210\n",
      "2017-10-24 16:28:22.181475 combinations 4 : 50 / 210\n",
      "2017-10-24 16:28:22.505434 combinations 4 : 100 / 210\n",
      "2017-10-24 16:28:22.860465 combinations 4 : 150 / 210\n",
      "2017-10-24 16:28:23.252436 combinations 4 : 200 / 210\n",
      "2017-10-24 16:28:23.337473 combinations 5 : 0 / 252\n",
      "2017-10-24 16:28:23.771432 combinations 5 : 50 / 252\n",
      "2017-10-24 16:28:24.243438 combinations 5 : 100 / 252\n",
      "2017-10-24 16:28:24.752433 combinations 5 : 150 / 252\n",
      "2017-10-24 16:28:25.297436 combinations 5 : 200 / 252\n",
      "2017-10-24 16:28:25.874439 combinations 5 : 250 / 252\n",
      "2017-10-24 16:28:26.060432 combinations 2 : 0 / 45\n",
      "2017-10-24 16:28:26.402471 combinations 3 : 0 / 120\n",
      "2017-10-24 16:28:26.848433 combinations 3 : 50 / 120\n",
      "2017-10-24 16:28:27.380440 combinations 3 : 100 / 120\n",
      "2017-10-24 16:28:27.617472 combinations 4 : 0 / 210\n",
      "2017-10-24 16:28:28.263470 combinations 4 : 50 / 210\n",
      "2017-10-24 16:28:28.998436 combinations 4 : 100 / 210\n",
      "2017-10-24 16:28:29.815471 combinations 4 : 150 / 210\n",
      "2017-10-24 16:28:30.721438 combinations 4 : 200 / 210\n",
      "2017-10-24 16:28:30.910437 combinations 5 : 0 / 252\n",
      "2017-10-24 16:28:31.918469 combinations 5 : 50 / 252\n",
      "2017-10-24 16:28:32.997463 combinations 5 : 100 / 252\n",
      "2017-10-24 16:28:34.164436 combinations 5 : 150 / 252\n",
      "2017-10-24 16:28:35.429470 combinations 5 : 200 / 252\n",
      "2017-10-24 16:28:36.765436 combinations 5 : 250 / 252\n",
      "2017-10-24 16:28:37.761442 combinations 2 : 0 / 28\n",
      "2017-10-24 16:28:39.170474 combinations 3 : 0 / 56\n",
      "2017-10-24 16:28:41.860436 combinations 3 : 50 / 56\n",
      "2017-10-24 16:28:42.213470 combinations 4 : 0 / 70\n",
      "2017-10-24 16:28:45.183435 combinations 4 : 50 / 70\n",
      "2017-10-24 16:28:46.459472 combinations 5 : 0 / 56\n",
      "2017-10-24 16:28:49.787432 combinations 5 : 50 / 56\n",
      "2017-10-24 16:28:50.226474 combinations 6 : 0 / 28\n",
      "\t Predicted -1 but was 1 : 0.5922480620155038\n",
      "3 0 Train Accuracy: 0.845177664975\n",
      "3 0 Test Accuracy: 0.832680686488\n",
      "2017-10-24 16:28:59.700433 combinations 2 : 0 / 28\n",
      "2017-10-24 16:29:01.136435 combinations 3 : 0 / 56\n",
      "2017-10-24 16:29:04.113437 combinations 3 : 50 / 56\n",
      "2017-10-24 16:29:04.481469 combinations 4 : 0 / 70\n",
      "2017-10-24 16:29:07.386471 combinations 4 : 50 / 70\n",
      "2017-10-24 16:29:08.635462 combinations 5 : 0 / 56\n",
      "2017-10-24 16:29:11.887436 combinations 5 : 50 / 56\n",
      "2017-10-24 16:29:12.295435 combinations 6 : 0 / 28\n",
      "2017-10-24 16:29:16.318438 combinations 2 : 0 / 28\n",
      "2017-10-24 16:29:19.534434 combinations 3 : 0 / 56\n",
      "2017-10-24 16:29:25.857135 combinations 3 : 50 / 56\n",
      "2017-10-24 16:29:26.672171 combinations 4 : 0 / 70\n",
      "2017-10-24 16:29:33.233193 combinations 4 : 50 / 70\n",
      "2017-10-24 16:29:36.039352 combinations 5 : 0 / 56\n",
      "2017-10-24 16:29:43.389215 combinations 5 : 50 / 56\n",
      "2017-10-24 16:29:44.312177 combinations 6 : 0 / 28\n",
      "2017-10-24 16:29:48.749175 combinations 2 : 0 / 45\n",
      "2017-10-24 16:29:48.923214 combinations 3 : 0 / 120\n",
      "2017-10-24 16:29:49.125215 combinations 3 : 50 / 120\n",
      "2017-10-24 16:29:49.355214 combinations 3 : 100 / 120\n",
      "2017-10-24 16:29:49.452182 combinations 4 : 0 / 210\n",
      "2017-10-24 16:29:49.716184 combinations 4 : 50 / 210\n",
      "2017-10-24 16:29:50.008215 combinations 4 : 100 / 210\n",
      "2017-10-24 16:29:50.301177 combinations 4 : 150 / 210\n",
      "2017-10-24 16:29:50.608175 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.9857142857142858\n",
      "3 1 Train Accuracy: 0.954406779661\n",
      "3 1 Test Accuracy: 0.918644067797\n",
      "2017-10-24 16:29:51.838182 combinations 2 : 0 / 45\n",
      "2017-10-24 16:29:52.025175 combinations 3 : 0 / 120\n",
      "2017-10-24 16:29:52.232178 combinations 3 : 50 / 120\n",
      "2017-10-24 16:29:52.458179 combinations 3 : 100 / 120\n",
      "2017-10-24 16:29:52.552181 combinations 4 : 0 / 210\n",
      "2017-10-24 16:29:52.799228 combinations 4 : 50 / 210\n",
      "2017-10-24 16:29:53.071175 combinations 4 : 100 / 210\n",
      "2017-10-24 16:29:53.359215 combinations 4 : 150 / 210\n",
      "2017-10-24 16:29:53.666222 combinations 4 : 200 / 210\n",
      "2017-10-24 16:29:53.942179 combinations 2 : 0 / 45\n",
      "2017-10-24 16:29:54.322214 combinations 3 : 0 / 120\n",
      "2017-10-24 16:29:54.779176 combinations 3 : 50 / 120\n",
      "2017-10-24 16:29:55.276214 combinations 3 : 100 / 120\n",
      "2017-10-24 16:29:55.489180 combinations 4 : 0 / 210\n",
      "2017-10-24 16:29:56.041215 combinations 4 : 50 / 210\n",
      "2017-10-24 16:29:56.632179 combinations 4 : 100 / 210\n",
      "2017-10-24 16:29:57.269175 combinations 4 : 150 / 210\n",
      "2017-10-24 16:29:57.938175 combinations 4 : 200 / 210\n",
      "Count: 250000\n",
      "Train Accuracy: 0.841048010282\n",
      "Test Accuracy: 0.836445133517\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize variables to submit data, this includes the id.\n",
    "It is important as the data will be separated depending on its features and category\n",
    "\"\"\"\n",
    "count = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "# For each category in PRI_num_jet and if they have or not NA\n",
    "for numjet in range(0, 4):\n",
    "    for index in range(0, 2):\n",
    "        # Get the x, y and ID\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        # Get the optimal weights and accuracy\n",
    "        w, predict_threshold, accuracy_train_k, accuracy_test_k = build_best_model(x_, y_, numjet, index)\n",
    "        \n",
    "        # Get the number of elements in that category\n",
    "        number_of_el = len(y_)\n",
    "\n",
    "        # Add the accuracy in proportion to the number of elements (max 1 if all elements in 1 category)\n",
    "        accuracy_train += accuracy_train_k * number_of_el\n",
    "        accuracy_test += accuracy_test_k * number_of_el\n",
    "        \n",
    "        # PRint training and testing accuracy\n",
    "        print(numjet, index, \"Train Accuracy: \" + str(accuracy_train_k))\n",
    "        print(numjet, index, \"Test Accuracy: \" + str(accuracy_test_k))\n",
    "        \n",
    "        # Count the number of elements\n",
    "        count += number_of_el\n",
    "  \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2, numjet, index)\n",
    "        pred_y2 = predict_labels(w, sub_x2, predict_threshold)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "        \n",
    "        sub_x = build_features(sub_x, numjet, index)\n",
    "        pred_y = predict_labels(w, sub_x, predict_threshold)\n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000 250000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84061200000000003"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total accuracy in our train set\n",
    "def get_accuracy_ids(result_y, result_ids, y, ids):\n",
    "    stacked = np.column_stack((ids, y))\n",
    "    stacked = stacked[stacked[:,0].argsort()]\n",
    "    stacked_pred = np.column_stack((result_ids, result_y))\n",
    "    stacked_pred = stacked_pred[stacked_pred[:,0].argsort()]\n",
    "    \n",
    "    print(len(stacked_pred), len(stacked))\n",
    "    unique, counts = np.unique((stacked == stacked_pred)[:, 1], return_counts=True)\n",
    "    return dict(zip(unique, counts))[True] / len(y)\n",
    "\n",
    "get_accuracy_ids(result_y, result_ids, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created !\n"
     ]
    }
   ],
   "source": [
    "# Create submission csv file\n",
    "submission_stacked = np.column_stack((submission_ids, submission_y))\n",
    "submission_stacked = submission_stacked[submission_stacked[:,0].argsort()]\n",
    "create_csv_submission(submission_stacked[:,0], submission_stacked[:,1], \"datas/submission.csv\")\n",
    "print('Submission file created !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model for specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "# Manually choose the categories\n",
    "x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, 0, 0)\n",
    "\n",
    "def build_polynomial2(x, max_degree):\n",
    "    polynomial_x = x\n",
    "    # Create new features with the tanh of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.tanh(x)), axis=1)\n",
    "    # Create new features with the ln of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.log(np.abs(x))), axis=1)\n",
    "    # Create new features with the square root of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x))), axis=1)\n",
    "    \n",
    "    # Create polynomials of max_degree of the new data\n",
    "    for degree in range(2, max_degree + 1):\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x, degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x), degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x)), degree)), axis=1)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "# Build combinations\n",
    "polynomial_x = normalize(x_)\n",
    "polynomial_x = build_polynomial2(polynomial_x, 3)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 2, 8)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 3, 8)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 4, 8)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 5, 8)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 6, 8)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 7, 8)\n",
    "\n",
    "predict_threshold = -0.00\n",
    "\n",
    "# 4.52035365636e-07 0.813863667164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here to test the accuracy of one specific classifier\n",
    "# Find best lambdas\n",
    "lambdas = np.logspace(-8, 0, 30)\n",
    "best_accuracy = 0\n",
    "best_lambda = 0\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_lambda = lambda_\n",
    "    print(\"Lambdas:\", lambda_, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_lambda, best_accuracy)\n",
    "lambda_ = best_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find best threshold\n",
    "threshs = np.linspace(0, -0.4, num=100)\n",
    "best_accuracy = 0\n",
    "best_thresh = 0\n",
    "for thresh in threshs:\n",
    "    predict_threshold = thresh\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_thresh = thresh\n",
    "    print(\"Thresh:\", thresh, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_thresh, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
