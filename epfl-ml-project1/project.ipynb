{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num_column_index = 22\n",
    "def group_by_jet_num(x, y):\n",
    "    jet_num_x_dict = dict()\n",
    "    jet_num_y_dict = dict()\n",
    "    \n",
    "    for jet_num in range(0, 4):\n",
    "        jet_num_x_dict[jet_num] = []\n",
    "        jet_num_y_dict[jet_num] = []\n",
    "\n",
    "    for row_index, row in enumerate(x):\n",
    "        jet_num = row[jet_num_column_index]\n",
    "        jet_num_x_dict[jet_num].append(row)\n",
    "        jet_num_y_dict[jet_num].append(y[row_index])\n",
    "        \n",
    "    \n",
    "    for jet_num in jet_num_x_dict:\n",
    "        jet_num_x_dict[jet_num] = np.array(jet_num_x_dict[jet_num])\n",
    "        jet_num_y_dict[jet_num] = np.array(jet_num_y_dict[jet_num])\n",
    "\n",
    "        \n",
    "        print(jet_num, jet_num_x_dict[jet_num].shape, jet_num_y_dict[jet_num].shape)\n",
    "        \n",
    "    return jet_num_x_dict, jet_num_y_dict\n",
    "\n",
    "    \n",
    "jet_num_x_dict, jet_num_y_dict = group_by_jet_num(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column with same value (0 values last)\n",
    "def remove_same_value_col(type_of_x_dict):\n",
    "    print(\"\\tRemove col : \")\n",
    "    for NaN_col_str in type_of_x_dict:\n",
    "        x = type_of_x_dict[NaN_col_str]\n",
    "        col_to_remove = []\n",
    "        for col in range(0, x.shape[1]):\n",
    "            if np.unique(x[:, col]).size == 1:\n",
    "                print('\\t', NaN_col_str, col, x[:, col])\n",
    "                col_to_remove.append(col)\n",
    "                \n",
    "        type_of_x_dict[NaN_col_str] = np.delete(x, col_to_remove, axis=1)\n",
    "        \n",
    "    return type_of_x_dict\n",
    "        \n",
    "\n",
    "def group_by_NaN_column(x, y):\n",
    "    rows_with_NaN = set(\"\")\n",
    "    \n",
    "    type_of_x_dict = dict()\n",
    "    type_of_y_dict = dict()\n",
    "\n",
    "    for row_index, row in enumerate(x):\n",
    "        columns_with_NaN = []\n",
    "        for col_index, feature in enumerate(row):\n",
    "            if feature == -999:\n",
    "                columns_with_NaN.append(col_index)\n",
    "            \n",
    "        tuple_str = str(tuple(columns_with_NaN))\n",
    "        if tuple_str in type_of_x_dict:\n",
    "            type_of_x_dict[tuple_str].append(row)\n",
    "            type_of_y_dict[tuple_str].append(y[row_index])\n",
    "        else:\n",
    "            type_of_x_dict[tuple_str] = [row]\n",
    "            type_of_y_dict[tuple_str] = [y[row_index]]\n",
    "    \n",
    "    for type_of_rows in type_of_x_dict:\n",
    "        type_of_x_dict[type_of_rows] = np.array(type_of_x_dict[type_of_rows])\n",
    "        type_of_y_dict[type_of_rows] = np.array(type_of_y_dict[type_of_rows])\n",
    "        type_of_y_dict[type_of_rows] = type_of_y_dict[type_of_rows].reshape(type_of_y_dict[type_of_rows].shape[0], 1)\n",
    "        \n",
    "        type_of_x_dict[type_of_rows] = np.delete(type_of_x_dict[type_of_rows], [col for col in eval(type_of_rows)], axis=1)\n",
    "        \n",
    "        print(type_of_rows, type_of_x_dict[type_of_rows].shape, type_of_y_dict[type_of_rows].shape)\n",
    "        \n",
    "    \n",
    "    type_of_x_dict = remove_same_value_col(type_of_x_dict)\n",
    "        \n",
    "    return type_of_x_dict, type_of_y_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet_num_key in jet_num_x_dict:\n",
    "    x = jet_num_x_dict[jet_num_key]\n",
    "    y = jet_num_y_dict[jet_num_key]\n",
    "    \n",
    "    print(\"num_jet:\", jet_num_key)\n",
    "    jet_num_x_dict[jet_num_key], jet_num_y_dict[jet_num_key] = group_by_NaN_column(x, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, numjet, index):\n",
    "    x = jet_num_x_dict[numjet][list(jet_num_x_dict[numjet])[index]]\n",
    "    y = jet_num_y_dict[numjet][list(jet_num_y_dict[numjet])[index]]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "numjet = 1\n",
    "index = 0\n",
    "x, y = get_data_numjet(jet_num_x_dict, jet_num_y_dict, numjet, index)\n",
    "x = normalize(x)\n",
    "\n",
    "train_x, train_y, test_x, test_y = separate_set(x, y)\n",
    "\n",
    "polynomial_x = x\n",
    "polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "train_x, train_y, test_x, test_y = separate_set(polynomial_x, y)\n",
    "\n",
    "lambda_ = find_best_ridge_lambda(train_y, train_x, test_x, test_y)\n",
    "w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "print(\"Lambda:\" + str(lambda_))\n",
    "print(\"Loss: \" + str(loss))\n",
    "print(\"Accuracy: \" + str(get_accuracy(train_x, train_y, w)))\n",
    "print(\"Accuracy: \" + str(get_accuracy(test_x, test_y, w)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_NaN(x, y, delete_columns=True, delete_rows=False):\n",
    "    columns_with_NaN = set(\"\")\n",
    "    rows_with_NaN = set(\"\")\n",
    "    for row_index, row in enumerate(x):\n",
    "        for col_index, feature in enumerate(row):\n",
    "            if feature == -999:\n",
    "                columns_with_NaN.add(col_index)\n",
    "                rows_with_NaN.add(row_index)\n",
    "\n",
    "    if delete_columns:\n",
    "        x = np.delete(x, [col for col in columns_with_NaN], axis=1)\n",
    "        print(\"Cleaned \" + str(len(columns_with_NaN)) + \" columns\")\n",
    "\n",
    "    if delete_rows:\n",
    "        x = np.delete(x, [row for row in rows_with_NaN], axis=0)\n",
    "        y = np.delete(y, [row for row in rows_with_NaN], axis=0)\n",
    "        print(\"Cleaned \" + str(len(rows_with_NaN)) + \" rows\")\n",
    "\n",
    "        \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportion_of_NaN(x):\n",
    "    nb_of_nan = np.zeros(30)\n",
    "    for row in x:\n",
    "        for i,feature in enumerate(row):\n",
    "            if feature == -999:\n",
    "                nb_of_nan[i] += 1\n",
    "        \n",
    "    return nb_of_nan / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, x2, _ = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "print(proportion_of_NaN(x2) - proportion_of_NaN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportion_of_NaN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.mean(axis=0)) / (x.std(axis=0) + 0.0000000001)\n",
    "\n",
    "\n",
    "def preprocess_data(x, y):\n",
    "    x, y = remove_NaN(x, y, delete_columns=False)\n",
    "    x = normalize(x)\n",
    "    return x, y\n",
    "x, y = preprocess_data(x, y)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_set(x, y):\n",
    "    x_and_y = np.concatenate((y.reshape((y.shape[0], 1)), x), axis=1)\n",
    "    np.random.shuffle(x_and_y)\n",
    "    \n",
    "    count = x_and_y.shape[0]\n",
    "    last_train_index = int(count * 0.95)\n",
    "    \n",
    "    train_set = x_and_y[0:last_train_index, :]\n",
    "    test_set = x_and_y[last_train_index:, :]\n",
    "    \n",
    "    train_y = train_set[:, 0]\n",
    "    test_y = test_set[:, 0]\n",
    "\n",
    "    train_x = train_set[:, 1:]\n",
    "    test_x = test_set[:, 1:]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = separate_set(x, y)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_init = np.random.rand(x.shape[1])\n",
    "w, loss = least_squares_GD(train_y, train_x, w_init, max_iters=100, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(train_y, train_x, w_init, 100, gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(test_x, test_y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "submission_x = submission_x[:, :15] # Removed all the primary\n",
    "submission_x = preprocess_data(submission_x)\n",
    "\n",
    "submission_x = build_polynomial(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 2)\n",
    "submission_x = build_combinations_lvl(submission_x, 3)\n",
    "submission_x = build_combinations_lvl(submission_x, 4)\n",
    "submission_x = build_combinations_lvl(submission_x, 5)\n",
    "submission_x = build_combinations_lvl(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 7)\n",
    "submission_x = build_combinations_lvl(submission_x, 8)\n",
    "\n",
    "pred_y = predict_labels(w, submission_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(submission_ids, pred_y, \"datas/submission.csv\")\n",
    "print('Done !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/a/7941594/4810319\n",
    "def main():\n",
    "    np.random.seed(1977)\n",
    "    numvars, numdata = 5, 100\n",
    "    data = 10 * np.random.random((numvars, numdata))\n",
    "    data = x[0:300, 0:7].T\n",
    "    print(x[0:200, 7])\n",
    "    fig = scatterplot_matrix(data, ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet'],\n",
    "            linestyle='none', marker='o', color='black', mfc='none')\n",
    "    fig.suptitle('Simple Scatterplot Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def scatterplot_matrix(data, names, **kwargs):\n",
    "    \"\"\"Plots a scatterplot matrix of subplots.  Each row of \"data\" is plotted\n",
    "    against other rows, resulting in a nrows by nrows grid of subplots with the\n",
    "    diagonal subplots labeled with \"names\".  Additional keyword arguments are\n",
    "    passed on to matplotlib's \"plot\" command. Returns the matplotlib figure\n",
    "    object containg the subplot grid.\"\"\"\n",
    "    numvars, numdata = data.shape\n",
    "    fig, axes = plt.subplots(nrows=numvars, ncols=numvars, figsize=(8,8))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        # Hide all ticks and labels\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "        # Set up ticks only on one side for the \"edge\" subplots...\n",
    "        if ax.is_first_col():\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "        if ax.is_last_col():\n",
    "            ax.yaxis.set_ticks_position('right')\n",
    "        if ax.is_first_row():\n",
    "            ax.xaxis.set_ticks_position('top')\n",
    "        if ax.is_last_row():\n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    # Plot the data.\n",
    "    for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "        for x, y in [(i,j), (j,i)]:\n",
    "            axes[x,y].plot(data[x], data[y], **kwargs)\n",
    "\n",
    "    # Label the diagonal subplots...\n",
    "    for i, label in enumerate(names):\n",
    "        axes[i,i].annotate(label, (0.5, 0.5), xycoords='axes fraction',\n",
    "                ha='center', va='center')\n",
    "\n",
    "    # Turn on the proper x or y axes ticks.\n",
    "    for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n",
    "        axes[j,i].xaxis.set_visible(True)\n",
    "        axes[i,j].yaxis.set_visible(True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    gram = tx.T.dot(tx)\n",
    "    print(\"Rank: \" + str(np.linalg.matrix_rank(gram)))\n",
    "    w = np.linalg.inv(gram).dot(tx.T).dot(y)\n",
    "    return w, compute_loss(y, tx, w)\n",
    "    \n",
    "w, loss = least_squares(train_y, train_x)\n",
    "print(\"Loss: \" + str(loss))\n",
    "print(\"Accuracy: \" + str(get_accuracy(train_x, train_y, w)))\n",
    "print(\"Accuracy: \" + str(get_accuracy(test_x, test_y, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    gram = tx.T.dot(tx)\n",
    "    lambda_prime = 2 * len(y) * lambda_\n",
    "    I = np.identity(len(gram))\n",
    "    w = np.linalg.inv(gram + np.dot(lambda_prime, I)).dot(tx.T).dot(y)\n",
    "    return w, compute_loss(y, tx, w)\n",
    "    \n",
    "def find_best_ridge_lambda(train_y, train_x, test_x, test_y):\n",
    "    step = 0.0001\n",
    "    lambda_ = 0\n",
    "    best_accuracy = 0\n",
    "    best_lambda = 0\n",
    "    for i in range(0, int(0.001/step)):\n",
    "        w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "\n",
    "        accuracy = get_accuracy(test_x, test_y, w)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_lambda = lambda_\n",
    "            print(lambda_, accuracy)\n",
    "\n",
    "        lambda_ += step\n",
    "    \n",
    "    return best_lambda\n",
    "    \n",
    "lambda_ = find_best_ridge_lambda(train_y, train_x, test_x, test_y)\n",
    "# lambda_ = 0.03\n",
    "w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "print(\"Lambda:\" + str(lambda_))\n",
    "print(\"Loss: \" + str(loss))\n",
    "print(\"Accuracy: \" + str(get_accuracy(train_x, train_y, w)))\n",
    "print(\"Accuracy: \" + str(get_accuracy(test_x, test_y, w)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_polynomial(x, max_degree):\n",
    "    polynomial_x = x\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.tanh(x)), axis=1)\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.log(np.abs(x))), axis=1)\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x))), axis=1)\n",
    "    for degree in range(2, max_degree +1):\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x, degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x), degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x)), degree)), axis=1)\n",
    "\n",
    "    return polynomial_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "def build_combinations(x):\n",
    "    columns_index = np.array(range(0, 19))\n",
    "    combinations = list(it.combinations(np.unique(columns_index), 2))\n",
    "\n",
    "    polynomial_x = x\n",
    "    for col1, col2 in combinations:\n",
    "        new_col = x[:, col1] * x[:, col2]\n",
    "        new_col = new_col.reshape(new_col.shape[0], 1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, new_col), axis=1)\n",
    "    \n",
    "    return polynomial_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_combinations_lvl(x, lvl):\n",
    "    columns_index = np.array(range(0, 21))\n",
    "    combinations = list(it.combinations(np.unique(columns_index), lvl))\n",
    "\n",
    "    polynomial_x = x\n",
    "    for ind, cols in enumerate(combinations):\n",
    "        new_col = 1\n",
    "        for col in cols:\n",
    "            new_col *= x[:, col]\n",
    "        new_col = new_col.reshape(new_col.shape[0], 1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, new_col), axis=1)\n",
    "        \n",
    "        if ind % 50 == 0:\n",
    "            print(datetime.now(), \"combinations\", lvl, \":\", ind, \"/\", len(combinations))\n",
    "    \n",
    "    return polynomial_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (Add more features)\n",
    "polynomial_x = x\n",
    "# polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 2)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 3)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 4)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 5)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 7)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 8)\n",
    "\n",
    "train_x, train_y, test_x, test_y = separate_set(polynomial_x, y)\n",
    "\n",
    "polynomial_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
