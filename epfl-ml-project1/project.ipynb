{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "from features_engineering import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from group_by import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (227458, 30) (227458,) (227458,)\n",
      "1 (175338, 30) (175338,) (175338,)\n",
      "2 (114648, 30) (114648,) (114648,)\n",
      "3 (50794, 30) (50794,) (50794,)\n",
      "num_jet: 0\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (59263, 19) (59263, 1) (59263, 1)\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (168195, 20) (168195, 1) (168195, 1)\n",
      "\tRemove col : \n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (158095, 23) (158095, 1) (158095, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (17243, 22) (17243, 1) (17243, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (107905, 30) (107905, 1) (107905, 1)\n",
      "(0,) (6743, 29) (6743, 1) (6743, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (47555, 30) (47555, 1) (47555, 1)\n",
      "(0,) (3239, 29) (3239, 1) (3239, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "sub_jet_num_x_dict, sub_jet_num_y_dict, sub_jet_num_ids_dict = group_by_jetnum_NaN(submission_x, submission_y, submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (99913, 30) (99913,) (99913,)\n",
      "1 (77544, 30) (77544,) (77544,)\n",
      "2 (50379, 30) (50379,) (50379,)\n",
      "3 (22164, 30) (22164,) (22164,)\n",
      "num_jet: 0\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (73790, 20) (73790, 1) (73790, 1)\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (26123, 19) (26123, 1) (26123, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (69982, 23) (69982, 1) (69982, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (7562, 22) (7562, 1) (7562, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (47427, 30) (47427, 1) (47427, 1)\n",
      "(0,) (2952, 29) (2952, 1) (2952, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (20687, 30) (20687, 1) (20687, 1)\n",
      "(0,) (1477, 29) (1477, 1) (1477, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict = group_by_jetnum_NaN(x, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea : Unbalance data\n",
    "# Check misclassified data\n",
    "\n",
    "# Need to test on two group of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false(x, y, w):\n",
    "    pred_y = predict_labels(w, x)\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "    \n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x):\n",
    "    polynomial_x = normalize(x)\n",
    "    polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "#     polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "    return polynomial_x\n",
    "\n",
    "\n",
    "count = 0\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "for numjet in range(0, 3):\n",
    "    for index in range(0, 1):\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        polynomial_x = build_features(x_)\n",
    "        train_x, train_y, test_x, test_y = separate_set(polynomial_x, y_)\n",
    "\n",
    "        lambda_ = find_best_ridge_lambda(train_y, train_x, test_x, test_y)\n",
    "        w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "        \n",
    "        number_of_el = len(y_)\n",
    "        accuracy_train += get_accuracy(train_x, train_y, w) * number_of_el\n",
    "        accuracy_test += get_accuracy(test_x, test_y, w) * number_of_el\n",
    "        \n",
    "        print(\"\\t Predicted -1 but was 1 :\", get_false(test_x, test_y, w))\n",
    "        \n",
    "        count += number_of_el\n",
    "        \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2)\n",
    "        pred_y2 = predict_labels(w, sub_x2)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "\n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x = build_features(sub_x)\n",
    "        pred_y = predict_labels(w, sub_x)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(submission_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, x2, _ = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "print(proportion_of_NaN(x2) - proportion_of_NaN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportion_of_NaN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_init = np.random.rand(x.shape[1])\n",
    "w, loss = least_squares_GD(train_y, train_x, w_init, max_iters=100, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(train_y, train_x, w_init, 100, gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(test_x, test_y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "submission_x = submission_x[:, :15] # Removed all the primary\n",
    "submission_x = preprocess_data(submission_x)\n",
    "\n",
    "submission_x = build_polynomial(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 2)\n",
    "submission_x = build_combinations_lvl(submission_x, 3)\n",
    "submission_x = build_combinations_lvl(submission_x, 4)\n",
    "submission_x = build_combinations_lvl(submission_x, 5)\n",
    "submission_x = build_combinations_lvl(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 7)\n",
    "submission_x = build_combinations_lvl(submission_x, 8)\n",
    "\n",
    "pred_y = predict_labels(w, submission_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(submission_ids, submission_y, \"datas/submission.csv\")\n",
    "print('Done !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/a/7941594/4810319\n",
    "def main():\n",
    "    np.random.seed(1977)\n",
    "    numvars, numdata = 5, 100\n",
    "    data = 10 * np.random.random((numvars, numdata))\n",
    "    data = x[0:300, 0:7].T\n",
    "    print(x[0:200, 7])\n",
    "    fig = scatterplot_matrix(data, ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet'],\n",
    "            linestyle='none', marker='o', color='black', mfc='none')\n",
    "    fig.suptitle('Simple Scatterplot Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def scatterplot_matrix(data, names, **kwargs):\n",
    "    \"\"\"Plots a scatterplot matrix of subplots.  Each row of \"data\" is plotted\n",
    "    against other rows, resulting in a nrows by nrows grid of subplots with the\n",
    "    diagonal subplots labeled with \"names\".  Additional keyword arguments are\n",
    "    passed on to matplotlib's \"plot\" command. Returns the matplotlib figure\n",
    "    object containg the subplot grid.\"\"\"\n",
    "    numvars, numdata = data.shape\n",
    "    fig, axes = plt.subplots(nrows=numvars, ncols=numvars, figsize=(8,8))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        # Hide all ticks and labels\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "        # Set up ticks only on one side for the \"edge\" subplots...\n",
    "        if ax.is_first_col():\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "        if ax.is_last_col():\n",
    "            ax.yaxis.set_ticks_position('right')\n",
    "        if ax.is_first_row():\n",
    "            ax.xaxis.set_ticks_position('top')\n",
    "        if ax.is_last_row():\n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    # Plot the data.\n",
    "    for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "        for x, y in [(i,j), (j,i)]:\n",
    "            axes[x,y].plot(data[x], data[y], **kwargs)\n",
    "\n",
    "    # Label the diagonal subplots...\n",
    "    for i, label in enumerate(names):\n",
    "        axes[i,i].annotate(label, (0.5, 0.5), xycoords='axes fraction',\n",
    "                ha='center', va='center')\n",
    "\n",
    "    # Turn on the proper x or y axes ticks.\n",
    "    for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n",
    "        axes[j,i].xaxis.set_visible(True)\n",
    "        axes[i,j].yaxis.set_visible(True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering (Add more features)\n",
    "polynomial_x = x\n",
    "# polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 2)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 3)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 4)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 5)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 7)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 8)\n",
    "\n",
    "train_x, train_y, test_x, test_y = separate_set(polynomial_x, y)\n",
    "\n",
    "polynomial_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000 250000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83430800000000005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_ids(result_y, result_ids, y, ids):\n",
    "    stacked = np.column_stack((ids, y))\n",
    "    stacked = stacked[stacked[:,0].argsort()]\n",
    "    stacked_pred = np.column_stack((result_ids, result_y))\n",
    "    stacked_pred = stacked_pred[stacked_pred[:,0].argsort()]\n",
    "    \n",
    "    print(len(stacked_pred), len(stacked))\n",
    "    unique, counts = np.unique((stacked == stacked_pred)[:, 1], return_counts=True)\n",
    "    return dict(zip(unique, counts))[True] / len(y)\n",
    "\n",
    "get_accuracy_ids(result_y, result_ids, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_stacked = np.column_stack((submission_ids, submission_y))\n",
    "submission_stacked = submission_stacked[submission_stacked[:,0].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "create_csv_submission(submission_stacked[:,0], submission_stacked[:,1], \"datas/submission.csv\")\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed=1):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def k_fold_cross_validation(y, x, k, lambda_):\n",
    "    \"\"\"return the accuracy of ridge regression.\"\"\"\n",
    "    \n",
    "    k_indices = build_k_indices(y, k)\n",
    "    accuracy_tr = []\n",
    "    accuracy_te = []\n",
    "    \n",
    "    accuracy_tr = []\n",
    "    accuracy_te = []\n",
    "\n",
    "    for i in range(0, k):\n",
    "        i = 0\n",
    "        \n",
    "        # get k'th subgroup in test, others in train:\n",
    "        x_test = x[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        x_train = np.array([]).reshape(0, x.shape[1])\n",
    "        y_train = np.array([]).reshape(0, 1)\n",
    "\n",
    "        for j in range(0, k):\n",
    "            if j != i:\n",
    "                x_train = np.concatenate((x_train, x[k_indices[j]]))\n",
    "                y_train = np.concatenate((y_train, y[k_indices[j]]))\n",
    "\n",
    "        # ridge regression:\n",
    "        w, loss = ridge_regression(y_train, x_train, lambda_)\n",
    "\n",
    "        # calculate the loss for train and test data\n",
    "        accuracy_tr.append(get_accuracy(x_train, y_train, w))\n",
    "        accuracy_te.append(get_accuracy(x_test, y_test, w))\n",
    "\n",
    "    return np.mean(accuracy_tr), np.mean(accuracy_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "lambda_ = 0.0001\n",
    "k_fold_cross_validation(y, x, k, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "lambdas = np.logspace(-4, 0, 15)\n",
    "x_features = build_features(x)\n",
    "for lambda_ in lambdas:\n",
    "    loss_tr, loss_te = k_fold_cross_validation(y, x_features, 4, lambda_)\n",
    "    rmse_tr += [loss_tr] \n",
    "    rmse_te += [loss_te]\n",
    "cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.00001\n",
    "train_x, train_y, test_x, test_y = separate_set(x, y)\n",
    "w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "get_accuracy(test_x, test_y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-13 09:46:22.300789 combinations 2 : 0 / 45\n",
      "2017-10-13 09:46:26.986319 combinations 3 : 0 / 120\n",
      "2017-10-13 09:46:34.607375 combinations 3 : 50 / 120\n",
      "2017-10-13 09:46:42.158927 combinations 3 : 100 / 120\n",
      "2017-10-13 09:46:45.469471 combinations 4 : 0 / 210\n",
      "2017-10-13 09:46:54.223069 combinations 4 : 50 / 210\n",
      "2017-10-13 09:47:04.744732 combinations 4 : 100 / 210\n",
      "2017-10-13 09:47:18.355026 combinations 4 : 150 / 210\n",
      "2017-10-13 09:47:33.695172 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.6796462513199577\n",
      "2017-10-13 09:48:11.127471 combinations 2 : 0 / 45\n",
      "2017-10-13 09:48:14.887473 combinations 3 : 0 / 120\n",
      "2017-10-13 09:48:20.244964 combinations 3 : 50 / 120\n",
      "2017-10-13 09:48:27.609177 combinations 3 : 100 / 120\n",
      "2017-10-13 09:48:30.900145 combinations 4 : 0 / 210\n",
      "2017-10-13 09:48:40.007746 combinations 4 : 50 / 210\n",
      "2017-10-13 09:48:56.744229 combinations 4 : 100 / 210\n",
      "2017-10-13 09:49:12.665971 combinations 4 : 150 / 210\n",
      "2017-10-13 09:49:27.835198 combinations 4 : 200 / 210\n",
      "2017-10-13 09:49:33.470953 combinations 2 : 0 / 45\n",
      "2017-10-13 09:49:43.332574 combinations 3 : 0 / 120\n",
      "2017-10-13 09:49:59.794318 combinations 3 : 50 / 120\n",
      "2017-10-13 09:50:19.599086 combinations 3 : 100 / 120\n",
      "2017-10-13 09:50:28.550003 combinations 4 : 0 / 210\n",
      "2017-10-13 09:50:57.320241 combinations 4 : 50 / 210\n",
      "2017-10-13 09:51:34.497532 combinations 4 : 100 / 210\n",
      "2017-10-13 09:52:31.461560 combinations 4 : 150 / 210\n",
      "2017-10-13 09:53:45.767739 combinations 4 : 200 / 210\n",
      "2017-10-13 09:54:01.062836 combinations 2 : 0 / 45\n",
      "2017-10-13 09:54:07.846903 combinations 3 : 0 / 120\n",
      "2017-10-13 09:54:17.421196 combinations 3 : 50 / 120\n",
      "2017-10-13 09:54:30.093358 combinations 3 : 100 / 120\n",
      "2017-10-13 09:54:35.526392 combinations 4 : 0 / 210\n",
      "2017-10-13 09:54:52.298679 combinations 4 : 50 / 210\n",
      "2017-10-13 09:55:12.681080 combinations 4 : 100 / 210\n",
      "2017-10-13 09:55:28.017753 combinations 4 : 150 / 210\n",
      "2017-10-13 09:55:43.770554 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.5947227788911156\n",
      "2017-10-13 09:56:10.977367 combinations 2 : 0 / 45\n",
      "2017-10-13 09:56:14.716492 combinations 3 : 0 / 120\n",
      "2017-10-13 09:56:19.642590 combinations 3 : 50 / 120\n",
      "2017-10-13 09:56:25.940348 combinations 3 : 100 / 120\n",
      "2017-10-13 09:56:29.255038 combinations 4 : 0 / 210\n",
      "2017-10-13 09:56:38.175896 combinations 4 : 50 / 210\n",
      "2017-10-13 09:56:47.698874 combinations 4 : 100 / 210\n",
      "2017-10-13 09:56:58.217443 combinations 4 : 150 / 210\n",
      "2017-10-13 09:57:09.371893 combinations 4 : 200 / 210\n",
      "2017-10-13 09:57:13.946044 combinations 2 : 0 / 45\n",
      "2017-10-13 09:57:22.359823 combinations 3 : 0 / 120\n",
      "2017-10-13 09:57:34.733033 combinations 3 : 50 / 120\n",
      "2017-10-13 09:57:49.002505 combinations 3 : 100 / 120\n",
      "2017-10-13 09:57:55.917660 combinations 4 : 0 / 210\n",
      "2017-10-13 09:58:19.656938 combinations 4 : 50 / 210\n",
      "2017-10-13 09:58:41.468634 combinations 4 : 100 / 210\n",
      "2017-10-13 09:59:05.053166 combinations 4 : 150 / 210\n",
      "2017-10-13 09:59:30.692347 combinations 4 : 200 / 210\n",
      "2017-10-13 09:59:36.521858 combinations 2 : 0 / 45\n",
      "2017-10-13 09:59:39.423934 combinations 3 : 0 / 120\n",
      "2017-10-13 09:59:43.350427 combinations 3 : 50 / 120\n",
      "2017-10-13 09:59:47.944035 combinations 3 : 100 / 120\n",
      "2017-10-13 09:59:50.058068 combinations 4 : 0 / 210\n",
      "2017-10-13 09:59:55.573220 combinations 4 : 50 / 210\n",
      "2017-10-13 10:00:02.445221 combinations 4 : 100 / 210\n",
      "2017-10-13 10:00:09.361218 combinations 4 : 150 / 210\n",
      "2017-10-13 10:00:17.090522 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.4898366819410175\n",
      "2017-10-13 10:00:34.543237 combinations 2 : 0 / 45\n",
      "2017-10-13 10:00:37.719389 combinations 3 : 0 / 120\n",
      "2017-10-13 10:00:41.564885 combinations 3 : 50 / 120\n",
      "2017-10-13 10:00:46.245927 combinations 3 : 100 / 120\n",
      "2017-10-13 10:00:48.359060 combinations 4 : 0 / 210\n",
      "2017-10-13 10:00:54.240174 combinations 4 : 50 / 210\n",
      "2017-10-13 10:01:01.040841 combinations 4 : 100 / 210\n",
      "2017-10-13 10:01:08.365091 combinations 4 : 150 / 210\n",
      "2017-10-13 10:01:16.138593 combinations 4 : 200 / 210\n",
      "2017-10-13 10:01:19.727693 combinations 2 : 0 / 45\n",
      "2017-10-13 10:01:26.293973 combinations 3 : 0 / 120\n",
      "2017-10-13 10:01:35.188877 combinations 3 : 50 / 120\n",
      "2017-10-13 10:01:45.736986 combinations 3 : 100 / 120\n",
      "2017-10-13 10:01:50.413611 combinations 4 : 0 / 210\n",
      "2017-10-13 10:02:03.404025 combinations 4 : 50 / 210\n",
      "2017-10-13 10:02:19.496376 combinations 4 : 100 / 210\n",
      "2017-10-13 10:02:38.233495 combinations 4 : 150 / 210\n",
      "2017-10-13 10:03:01.013148 combinations 4 : 200 / 210\n",
      "2017-10-13 10:03:05.466089 combinations 2 : 0 / 45\n",
      "2017-10-13 10:03:06.931606 combinations 3 : 0 / 120\n",
      "2017-10-13 10:03:08.852608 combinations 3 : 50 / 120\n",
      "2017-10-13 10:03:11.304697 combinations 3 : 100 / 120\n",
      "2017-10-13 10:03:12.342196 combinations 4 : 0 / 210\n",
      "2017-10-13 10:03:15.523744 combinations 4 : 50 / 210\n",
      "2017-10-13 10:03:19.230240 combinations 4 : 100 / 210\n",
      "2017-10-13 10:03:22.711239 combinations 4 : 150 / 210\n",
      "2017-10-13 10:03:26.265401 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.7163352630254216\n",
      "2017-10-13 10:03:35.742686 combinations 2 : 0 / 45\n",
      "2017-10-13 10:03:37.231826 combinations 3 : 0 / 120\n",
      "2017-10-13 10:03:39.161874 combinations 3 : 50 / 120\n",
      "2017-10-13 10:03:41.359876 combinations 3 : 100 / 120\n",
      "2017-10-13 10:03:42.353874 combinations 4 : 0 / 210\n",
      "2017-10-13 10:03:44.973930 combinations 4 : 50 / 210\n",
      "2017-10-13 10:03:48.049927 combinations 4 : 100 / 210\n",
      "2017-10-13 10:03:51.509965 combinations 4 : 150 / 210\n",
      "2017-10-13 10:03:56.402471 combinations 4 : 200 / 210\n",
      "2017-10-13 10:03:58.427048 combinations 2 : 0 / 45\n",
      "2017-10-13 10:04:02.308549 combinations 3 : 0 / 120\n",
      "2017-10-13 10:04:07.612566 combinations 3 : 50 / 120\n",
      "2017-10-13 10:04:14.528064 combinations 3 : 100 / 120\n",
      "2017-10-13 10:04:17.349065 combinations 4 : 0 / 210\n",
      "2017-10-13 10:04:25.047565 combinations 4 : 50 / 210\n",
      "2017-10-13 10:04:33.434855 combinations 4 : 100 / 210\n",
      "2017-10-13 10:04:42.720581 combinations 4 : 150 / 210\n",
      "2017-10-13 10:04:52.989769 combinations 4 : 200 / 210\n",
      "Count: 250000\n",
      "Train Accuracy: 0.831094644092\n",
      "Test Accuracy: 0.822849041696\n"
     ]
    }
   ],
   "source": [
    "def get_false(x, y, w):\n",
    "    pred_y = predict_labels(w, x)\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "    \n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x):\n",
    "    polynomial_x = normalize(x)\n",
    "    polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "for numjet in range(0, 4):\n",
    "    for index in range(0, 1):\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        polynomial_x = build_features(x_)\n",
    "        lambda_ = 0.0000001\n",
    "        accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, 5, lambda_)\n",
    "        \n",
    "        w, loss = ridge_regression(y_, polynomial_x, lambda_)\n",
    "        \n",
    "        number_of_el = len(y_)\n",
    "\n",
    "        accuracy_train += accuracy_train_k * number_of_el\n",
    "        accuracy_test += accuracy_test_k * number_of_el\n",
    "        \n",
    "        print(numjet, index, \"Train Accuracy: \" + str(accuracy_train_k))\n",
    "        print(numjet, index, \"Test Accuracy: \" + str(accuracy_test_k))\n",
    "        print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w))\n",
    "        \n",
    "        count += number_of_el\n",
    "  \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2)\n",
    "        pred_y2 = predict_labels(w, sub_x2)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "\n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x = build_features(sub_x)\n",
    "        pred_y = predict_labels(w, sub_x)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Train Accuracy: 0.81122103266\n",
      "0 0 Test Accuracy: 0.807697519989\n",
      "\t Predicted -1 but was 1 : 0.6275693546068708\n",
      "0 1 Train Accuracy: 0.949607580398\n",
      "0 1 Test Accuracy: 0.952335375191\n",
      "\t Predicted -1 but was 1 : 0.9384615384615385\n",
      "1 0 Train Accuracy: 0.800389396971\n",
      "1 0 Test Accuracy: 0.795370105744\n",
      "\t Predicted -1 but was 1 : 0.5537672696197123\n",
      "1 1 Train Accuracy: 0.922453703704\n",
      "1 1 Test Accuracy: 0.914021164021\n",
      "\t Predicted -1 but was 1 : 0.9465776293823038\n",
      "2 0 Train Accuracy: 0.836162361624\n",
      "2 0 Test Accuracy: 0.831839746969\n",
      "\t Predicted -1 but was 1 : 0.4451282051282051\n",
      "2 1 Train Accuracy: 0.925423728814\n",
      "2 1 Test Accuracy: 0.891525423729\n",
      "\t Predicted -1 but was 1 : 0.782608695652174\n",
      "3 0 Train Accuracy: 0.832547739908\n",
      "3 0 Test Accuracy: 0.829828378052\n",
      "\t Predicted -1 but was 1 : 0.5960704998555331\n",
      "3 1 Train Accuracy: 0.956779661017\n",
      "3 1 Test Accuracy: 0.891525423729\n",
      "\t Predicted -1 but was 1 : 0.987012987012987\n",
      "Count: 250000\n",
      "Train Accuracy: 0.834718585344\n",
      "Test Accuracy: 0.830472660906\n"
     ]
    }
   ],
   "source": [
    "def get_false(x, y, w):\n",
    "    pred_y = predict_labels(w, x)\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "    \n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x):\n",
    "    polynomial_x = normalize(x)\n",
    "    polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "#     polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "#     polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "#     polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "for numjet in range(0, 4):\n",
    "    for index in range(0, 2):\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        polynomial_x = build_features(x_)\n",
    "        lambda_ = 0.0000001\n",
    "        accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, 5, lambda_)\n",
    "        \n",
    "        w, loss = ridge_regression(y_, polynomial_x, lambda_)\n",
    "        \n",
    "        number_of_el = len(y_)\n",
    "\n",
    "        accuracy_train += accuracy_train_k * number_of_el\n",
    "        accuracy_test += accuracy_test_k * number_of_el\n",
    "        \n",
    "        print(numjet, index, \"Train Accuracy: \" + str(accuracy_train_k))\n",
    "        print(numjet, index, \"Test Accuracy: \" + str(accuracy_test_k))\n",
    "        \n",
    "        print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w))\n",
    "        \n",
    "        count += number_of_el\n",
    "  \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2)\n",
    "        pred_y2 = predict_labels(w, sub_x2)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "\n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x = build_features(sub_x)\n",
    "        pred_y = predict_labels(w, sub_x)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
