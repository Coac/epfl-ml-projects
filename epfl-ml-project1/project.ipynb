{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from features_engineering import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from group_by import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_y, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sub dataset \n",
    "- Group by numjet column (categorical data : (0, 1, 2, 3))\n",
    "- Group by the NaN columns\n",
    "\n",
    "We obtain at the end 8 datasets, one for each numjet and for each of these, 2 according to the NaN columns removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (227458, 30) (227458,) (227458,)\n",
      "1 (175338, 30) (175338,) (175338,)\n",
      "2 (114648, 30) (114648,) (114648,)\n",
      "3 (50794, 30) (50794,) (50794,)\n",
      "num_jet: 0\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (59263, 19) (59263, 1) (59263, 1)\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (168195, 20) (168195, 1) (168195, 1)\n",
      "\tRemove col : \n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (158095, 23) (158095, 1) (158095, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (17243, 22) (17243, 1) (17243, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (107905, 30) (107905, 1) (107905, 1)\n",
      "(0,) (6743, 29) (6743, 1) (6743, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (47555, 30) (47555, 1) (47555, 1)\n",
      "(0,) (3239, 29) (3239, 1) (3239, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "sub_jet_num_x_dict, sub_jet_num_y_dict, sub_jet_num_ids_dict = group_by_jetnum_NaN(submission_x, submission_y, submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (99913, 30) (99913,) (99913,)\n",
      "1 (77544, 30) (77544,) (77544,)\n",
      "2 (50379, 30) (50379,) (50379,)\n",
      "3 (22164, 30) (22164,) (22164,)\n",
      "num_jet: 0\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (73790, 20) (73790, 1) (73790, 1)\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (26123, 19) (26123, 1) (26123, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (69982, 23) (69982, 1) (69982, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (7562, 22) (7562, 1) (7562, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (47427, 30) (47427, 1) (47427, 1)\n",
      "(0,) (2952, 29) (2952, 1) (2952, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (20687, 30) (20687, 1) (20687, 1)\n",
      "(0,) (1477, 29) (1477, 1) (1477, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict = group_by_jetnum_NaN(x, y, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the best model for each of the sub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_false(x, y, w, predict_threshold):\n",
    "    \"\"\"Get the ratio of negative predictions over wrong predictions\"\"\"\n",
    "    \n",
    "    # Get the predicted values\n",
    "    pred_y = predict_labels(w, x, predict_threshold)\n",
    "    # Initialize at 0\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    \n",
    "    # If prediction is wrong, add 1, if prediction is wrong and negative, add 1\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "                \n",
    "    # Calculate which percentage of wrong predictions are due to negative value\n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    # Get the column number of the features that wil be removed\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    # Get the samples of the category numjet of PRI_num_jet and removed data\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x, numjet, index):\n",
    "    \"\"\"\n",
    "    Calculate different features depending on the data (category of PRI_num_jet and nan or not)\n",
    "    Which features are used has been done with trial and error to improve the loss\n",
    "    1. Normalize data\n",
    "    2. Build combinations\n",
    "    \"\"\"\n",
    "    if numjet == 0 and index == 0:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 6, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 7, 8)\n",
    "    elif numjet == 0 and index == 1:\n",
    "        x_numjet0_index1 = normalize(x)\n",
    "        polynomial_x = x_numjet0_index1\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.tanh(x_numjet0_index1)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x_numjet0_index1))), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x_numjet0_index1, 2)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x_numjet0_index1), 2)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x_numjet0_index1)), 2)), axis=1)\n",
    "    elif numjet == 1 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 2 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 2)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 3 and index == 0:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 5)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 8)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 6, 8)\n",
    "    elif numjet == 3 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "    else:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "def build_best_model(x_, y_, numjet, index):\n",
    "    \"\"\"\n",
    "    Build the best model with the best parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize k_fold and prediction threshold and build features\n",
    "    k = 5\n",
    "    predict_threshold = 0\n",
    "    polynomial_x = build_features(x_, numjet, index)\n",
    "\n",
    "    # Use the best lambda for best result\n",
    "    if numjet == 0 and index == 0:\n",
    "        lambda_ = 4.52035365636e-07\n",
    "    elif numjet == 0 and index == 1:\n",
    "        lambda_ = 1e-08\n",
    "    elif numjet == 1 and index == 1:\n",
    "        lambda_ = 0.137382379588\n",
    "    elif numjet == 2 and index == 1:\n",
    "        lambda_ = 0.0417531893656\n",
    "        predict_threshold = -0.0323232323232\n",
    "    elif numjet == 3 and index == 0:\n",
    "        lambda_ = 7.27895384398e-05\n",
    "    elif numjet == 3 and index == 1:\n",
    "        lambda_ = 0.529831690628\n",
    "    else:\n",
    "        lambda_ = 0.000001\n",
    "\n",
    "\n",
    "    #Gest the accuracy of test and train using k_fold_corss_validation\n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "    # Find optimal weights and loss with ridge regression\n",
    "    w, loss = ridge_regression(y_, polynomial_x, lambda_)\n",
    "\n",
    "    \n",
    "    print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "    \n",
    "    return w, predict_threshold, accuracy_train_k, accuracy_test_k\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-25 14:31:34.153280 combinations 2 : 0 / 28\n",
      "2017-10-25 14:31:36.342279 combinations 3 : 0 / 56\n",
      "2017-10-25 14:31:41.398287 combinations 3 : 50 / 56\n",
      "2017-10-25 14:31:42.165282 combinations 4 : 0 / 70\n",
      "2017-10-25 14:31:48.052607 combinations 4 : 50 / 70\n",
      "2017-10-25 14:31:50.668605 combinations 5 : 0 / 56\n",
      "2017-10-25 14:31:57.508564 combinations 5 : 50 / 56\n",
      "2017-10-25 14:31:58.483565 combinations 6 : 0 / 28\n",
      "2017-10-25 14:32:02.977569 combinations 7 : 0 / 8\n",
      "\t Predicted -1 but was 1 : 0.634313005143277\n",
      "0 0 Train Accuracy: 0.815696571351\n",
      "0 0 Test Accuracy: 0.814337986177\n",
      "2017-10-25 14:32:20.731569 combinations 2 : 0 / 28\n",
      "2017-10-25 14:32:22.790566 combinations 3 : 0 / 56\n",
      "2017-10-25 14:32:27.259608 combinations 3 : 50 / 56\n",
      "2017-10-25 14:32:27.861568 combinations 4 : 0 / 70\n",
      "2017-10-25 14:32:33.392564 combinations 4 : 50 / 70\n",
      "2017-10-25 14:32:35.840602 combinations 5 : 0 / 56\n",
      "2017-10-25 14:32:42.795601 combinations 5 : 50 / 56\n",
      "2017-10-25 14:32:43.670566 combinations 6 : 0 / 28\n",
      "2017-10-25 14:32:48.000566 combinations 7 : 0 / 8\n",
      "2017-10-25 14:32:51.916780 combinations 2 : 0 / 28\n",
      "2017-10-25 14:32:57.517434 combinations 3 : 0 / 56\n",
      "2017-10-25 14:33:10.654886 combinations 3 : 50 / 56\n",
      "2017-10-25 14:33:12.566888 combinations 4 : 0 / 70\n",
      "2017-10-25 14:33:28.369543 combinations 4 : 50 / 70\n",
      "2017-10-25 14:33:34.615513 combinations 5 : 0 / 56\n",
      "2017-10-25 14:33:52.579656 combinations 5 : 50 / 56\n",
      "2017-10-25 14:33:54.850645 combinations 6 : 0 / 28\n",
      "2017-10-25 14:34:06.385518 combinations 7 : 0 / 8\n",
      "\t Predicted -1 but was 1 : 0.9561200923787528\n",
      "0 1 Train Accuracy: 0.95047856049\n",
      "0 1 Test Accuracy: 0.949961715161\n",
      "2017-10-25 14:34:13.348519 combinations 2 : 0 / 45\n",
      "2017-10-25 14:34:17.475553 combinations 3 : 0 / 120\n",
      "2017-10-25 14:34:22.597556 combinations 3 : 50 / 120\n",
      "2017-10-25 14:34:28.890579 combinations 3 : 100 / 120\n",
      "2017-10-25 14:34:31.756548 combinations 4 : 0 / 210\n",
      "2017-10-25 14:34:39.061553 combinations 4 : 50 / 210\n",
      "2017-10-25 14:34:47.329583 combinations 4 : 100 / 210\n",
      "2017-10-25 14:34:57.328549 combinations 4 : 150 / 210\n",
      "2017-10-25 14:35:09.301548 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.5616155660377359\n",
      "1 0 Train Accuracy: 0.806441126036\n",
      "1 0 Test Accuracy: 0.802829379823\n",
      "2017-10-25 14:35:39.578014 combinations 2 : 0 / 45\n",
      "2017-10-25 14:35:44.474247 combinations 3 : 0 / 120\n",
      "2017-10-25 14:35:49.902785 combinations 3 : 50 / 120\n",
      "2017-10-25 14:35:56.619722 combinations 3 : 100 / 120\n",
      "2017-10-25 14:35:59.495405 combinations 4 : 0 / 210\n",
      "2017-10-25 14:36:06.934438 combinations 4 : 50 / 210\n",
      "2017-10-25 14:36:15.094404 combinations 4 : 100 / 210\n",
      "2017-10-25 14:36:25.730821 combinations 4 : 150 / 210\n",
      "2017-10-25 14:36:38.636056 combinations 4 : 200 / 210\n",
      "2017-10-25 14:36:43.392092 combinations 2 : 0 / 45\n",
      "2017-10-25 14:36:53.483060 combinations 3 : 0 / 120\n",
      "2017-10-25 14:37:06.226064 combinations 3 : 50 / 120\n",
      "2017-10-25 14:37:21.897966 combinations 3 : 100 / 120\n",
      "2017-10-25 14:37:28.510552 combinations 4 : 0 / 210\n",
      "2017-10-25 14:37:51.199534 combinations 4 : 50 / 210\n",
      "2017-10-25 14:38:11.077017 combinations 4 : 100 / 210\n",
      "2017-10-25 14:38:32.203014 combinations 4 : 150 / 210\n",
      "2017-10-25 14:38:55.269014 combinations 4 : 200 / 210\n",
      "2017-10-25 14:39:00.454014 combinations 2 : 0 / 45\n",
      "2017-10-25 14:39:00.880977 combinations 3 : 0 / 120\n",
      "2017-10-25 14:39:01.456982 combinations 3 : 50 / 120\n",
      "2017-10-25 14:39:02.094979 combinations 3 : 100 / 120\n",
      "2017-10-25 14:39:02.374978 combinations 4 : 0 / 210\n",
      "2017-10-25 14:39:03.125979 combinations 4 : 50 / 210\n",
      "2017-10-25 14:39:03.983012 combinations 4 : 100 / 210\n",
      "2017-10-25 14:39:05.098975 combinations 4 : 150 / 210\n",
      "2017-10-25 14:39:06.182013 combinations 4 : 200 / 210\n",
      "2017-10-25 14:39:06.410012 combinations 5 : 0 / 252\n",
      "2017-10-25 14:39:07.558015 combinations 5 : 50 / 252\n",
      "2017-10-25 14:39:08.796979 combinations 5 : 100 / 252\n",
      "2017-10-25 14:39:10.126975 combinations 5 : 150 / 252\n",
      "2017-10-25 14:39:11.576976 combinations 5 : 200 / 252\n",
      "2017-10-25 14:39:13.175020 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.9713740458015268\n",
      "1 1 Train Accuracy: 0.93167989418\n",
      "1 1 Test Accuracy: 0.921560846561\n",
      "2017-10-25 14:39:16.497977 combinations 2 : 0 / 45\n",
      "2017-10-25 14:39:16.984979 combinations 3 : 0 / 120\n",
      "2017-10-25 14:39:17.544976 combinations 3 : 50 / 120\n",
      "2017-10-25 14:39:18.345978 combinations 3 : 100 / 120\n",
      "2017-10-25 14:39:18.626978 combinations 4 : 0 / 210\n",
      "2017-10-25 14:39:19.407015 combinations 4 : 50 / 210\n",
      "2017-10-25 14:39:20.243982 combinations 4 : 100 / 210\n",
      "2017-10-25 14:39:21.194012 combinations 4 : 150 / 210\n",
      "2017-10-25 14:39:22.249979 combinations 4 : 200 / 210\n",
      "2017-10-25 14:39:22.471018 combinations 5 : 0 / 252\n",
      "2017-10-25 14:39:23.625013 combinations 5 : 50 / 252\n",
      "2017-10-25 14:39:24.876976 combinations 5 : 100 / 252\n",
      "2017-10-25 14:39:26.286981 combinations 5 : 150 / 252\n",
      "2017-10-25 14:39:27.769015 combinations 5 : 200 / 252\n",
      "2017-10-25 14:39:29.296979 combinations 5 : 250 / 252\n",
      "2017-10-25 14:39:29.716979 combinations 2 : 0 / 45\n",
      "2017-10-25 14:39:30.595011 combinations 3 : 0 / 120\n",
      "2017-10-25 14:39:31.766013 combinations 3 : 50 / 120\n",
      "2017-10-25 14:39:33.136978 combinations 3 : 100 / 120\n",
      "2017-10-25 14:39:33.747979 combinations 4 : 0 / 210\n",
      "2017-10-25 14:39:35.411014 combinations 4 : 50 / 210\n",
      "2017-10-25 14:39:37.462867 combinations 4 : 100 / 210\n",
      "2017-10-25 14:39:40.091704 combinations 4 : 150 / 210\n",
      "2017-10-25 14:39:42.703705 combinations 4 : 200 / 210\n",
      "2017-10-25 14:39:43.190703 combinations 5 : 0 / 252\n",
      "2017-10-25 14:39:46.187666 combinations 5 : 50 / 252\n",
      "2017-10-25 14:39:49.074668 combinations 5 : 100 / 252\n",
      "2017-10-25 14:39:52.160703 combinations 5 : 150 / 252\n",
      "2017-10-25 14:39:55.481667 combinations 5 : 200 / 252\n",
      "2017-10-25 14:39:59.045668 combinations 5 : 250 / 252\n",
      "2017-10-25 14:40:00.256710 combinations 2 : 0 / 45\n",
      "2017-10-25 14:40:03.613702 combinations 3 : 0 / 120\n",
      "2017-10-25 14:40:07.931704 combinations 3 : 50 / 120\n",
      "2017-10-25 14:40:12.832665 combinations 3 : 100 / 120\n",
      "2017-10-25 14:40:14.952703 combinations 4 : 0 / 210\n",
      "2017-10-25 14:40:20.710668 combinations 4 : 50 / 210\n",
      "2017-10-25 14:40:27.084707 combinations 4 : 100 / 210\n",
      "2017-10-25 14:40:34.079702 combinations 4 : 150 / 210\n",
      "2017-10-25 14:40:41.594669 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.4613196043896491\n",
      "2 0 Train Accuracy: 0.845118608329\n",
      "2 0 Test Accuracy: 0.839515023722\n",
      "2017-10-25 14:41:00.353703 combinations 2 : 0 / 45\n",
      "2017-10-25 14:41:03.712704 combinations 3 : 0 / 120\n",
      "2017-10-25 14:41:07.993668 combinations 3 : 50 / 120\n",
      "2017-10-25 14:41:12.953701 combinations 3 : 100 / 120\n",
      "2017-10-25 14:41:15.103668 combinations 4 : 0 / 210\n",
      "2017-10-25 14:41:20.807667 combinations 4 : 50 / 210\n",
      "2017-10-25 14:41:27.150670 combinations 4 : 100 / 210\n",
      "2017-10-25 14:41:34.092668 combinations 4 : 150 / 210\n",
      "2017-10-25 14:41:41.647669 combinations 4 : 200 / 210\n",
      "2017-10-25 14:41:45.444666 combinations 2 : 0 / 45\n",
      "2017-10-25 14:41:52.667704 combinations 3 : 0 / 120\n",
      "2017-10-25 14:42:01.854704 combinations 3 : 50 / 120\n",
      "2017-10-25 14:42:12.229711 combinations 3 : 100 / 120\n",
      "2017-10-25 14:42:16.704666 combinations 4 : 0 / 210\n",
      "2017-10-25 14:42:29.703670 combinations 4 : 50 / 210\n",
      "2017-10-25 14:42:45.752665 combinations 4 : 100 / 210\n",
      "2017-10-25 14:43:02.843665 combinations 4 : 150 / 210\n",
      "2017-10-25 14:43:20.766668 combinations 4 : 200 / 210\n",
      "2017-10-25 14:43:24.496668 combinations 2 : 0 / 45\n",
      "2017-10-25 14:43:24.643667 combinations 3 : 0 / 120\n",
      "2017-10-25 14:43:24.850666 combinations 3 : 50 / 120\n",
      "2017-10-25 14:43:25.083668 combinations 3 : 100 / 120\n",
      "2017-10-25 14:43:25.182690 combinations 4 : 0 / 210\n",
      "2017-10-25 14:43:25.478667 combinations 4 : 50 / 210\n",
      "2017-10-25 14:43:25.924681 combinations 4 : 100 / 210\n",
      "2017-10-25 14:43:26.351670 combinations 4 : 150 / 210\n",
      "2017-10-25 14:43:26.809667 combinations 4 : 200 / 210\n",
      "2017-10-25 14:43:26.898670 combinations 5 : 0 / 252\n",
      "2017-10-25 14:43:27.410665 combinations 5 : 50 / 252\n",
      "2017-10-25 14:43:27.970671 combinations 5 : 100 / 252\n",
      "2017-10-25 14:43:28.526666 combinations 5 : 150 / 252\n",
      "2017-10-25 14:43:29.242667 combinations 5 : 200 / 252\n",
      "2017-10-25 14:43:29.978702 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.8138297872340425\n",
      "2 1 Train Accuracy: 0.939491525424\n",
      "2 1 Test Accuracy: 0.904406779661\n",
      "2017-10-25 14:43:32.001665 combinations 2 : 0 / 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-25 14:43:32.160665 combinations 3 : 0 / 120\n",
      "2017-10-25 14:43:32.362666 combinations 3 : 50 / 120\n",
      "2017-10-25 14:43:32.594703 combinations 3 : 100 / 120\n",
      "2017-10-25 14:43:32.700665 combinations 4 : 0 / 210\n",
      "2017-10-25 14:43:32.993667 combinations 4 : 50 / 210\n",
      "2017-10-25 14:43:33.344667 combinations 4 : 100 / 210\n",
      "2017-10-25 14:43:33.729675 combinations 4 : 150 / 210\n",
      "2017-10-25 14:43:34.150665 combinations 4 : 200 / 210\n",
      "2017-10-25 14:43:34.238668 combinations 5 : 0 / 252\n",
      "2017-10-25 14:43:34.743666 combinations 5 : 50 / 252\n",
      "2017-10-25 14:43:35.252666 combinations 5 : 100 / 252\n",
      "2017-10-25 14:43:35.901667 combinations 5 : 150 / 252\n",
      "2017-10-25 14:43:36.470699 combinations 5 : 200 / 252\n",
      "2017-10-25 14:43:37.086668 combinations 5 : 250 / 252\n",
      "2017-10-25 14:43:37.275670 combinations 2 : 0 / 45\n",
      "2017-10-25 14:43:37.647672 combinations 3 : 0 / 120\n",
      "2017-10-25 14:43:38.125704 combinations 3 : 50 / 120\n",
      "2017-10-25 14:43:38.712670 combinations 3 : 100 / 120\n",
      "2017-10-25 14:43:38.964704 combinations 4 : 0 / 210\n",
      "2017-10-25 14:43:39.629666 combinations 4 : 50 / 210\n",
      "2017-10-25 14:43:40.387667 combinations 4 : 100 / 210\n",
      "2017-10-25 14:43:41.256669 combinations 4 : 150 / 210\n",
      "2017-10-25 14:43:42.221665 combinations 4 : 200 / 210\n",
      "2017-10-25 14:43:42.417671 combinations 5 : 0 / 252\n",
      "2017-10-25 14:43:43.513667 combinations 5 : 50 / 252\n",
      "2017-10-25 14:43:44.701670 combinations 5 : 100 / 252\n",
      "2017-10-25 14:43:45.876705 combinations 5 : 150 / 252\n",
      "2017-10-25 14:43:47.225704 combinations 5 : 200 / 252\n",
      "2017-10-25 14:43:48.656665 combinations 5 : 250 / 252\n",
      "2017-10-25 14:43:49.699665 combinations 2 : 0 / 28\n",
      "2017-10-25 14:43:51.109670 combinations 3 : 0 / 56\n",
      "2017-10-25 14:43:54.047703 combinations 3 : 50 / 56\n",
      "2017-10-25 14:43:54.386705 combinations 4 : 0 / 70\n",
      "2017-10-25 14:43:57.468668 combinations 4 : 50 / 70\n",
      "2017-10-25 14:43:58.821666 combinations 5 : 0 / 56\n",
      "2017-10-25 14:44:02.530702 combinations 5 : 50 / 56\n",
      "2017-10-25 14:44:03.023668 combinations 6 : 0 / 28\n",
      "\t Predicted -1 but was 1 : 0.5922480620155038\n",
      "3 0 Train Accuracy: 0.845177664975\n",
      "3 0 Test Accuracy: 0.832680686488\n",
      "2017-10-25 14:44:12.831675 combinations 2 : 0 / 28\n",
      "2017-10-25 14:44:14.221705 combinations 3 : 0 / 56\n",
      "2017-10-25 14:44:16.982704 combinations 3 : 50 / 56\n",
      "2017-10-25 14:44:17.325705 combinations 4 : 0 / 70\n",
      "2017-10-25 14:44:20.369667 combinations 4 : 50 / 70\n",
      "2017-10-25 14:44:21.660666 combinations 5 : 0 / 56\n",
      "2017-10-25 14:44:25.107695 combinations 5 : 50 / 56\n",
      "2017-10-25 14:44:25.531669 combinations 6 : 0 / 28\n",
      "2017-10-25 14:44:29.796702 combinations 2 : 0 / 28\n",
      "2017-10-25 14:44:33.026703 combinations 3 : 0 / 56\n",
      "2017-10-25 14:44:39.243668 combinations 3 : 50 / 56\n",
      "2017-10-25 14:44:40.033694 combinations 4 : 0 / 70\n",
      "2017-10-25 14:44:46.945668 combinations 4 : 50 / 70\n",
      "2017-10-25 14:44:49.872703 combinations 5 : 0 / 56\n",
      "2017-10-25 14:44:57.583705 combinations 5 : 50 / 56\n",
      "2017-10-25 14:44:58.566667 combinations 6 : 0 / 28\n",
      "2017-10-25 14:45:03.237703 combinations 2 : 0 / 45\n",
      "2017-10-25 14:45:03.409665 combinations 3 : 0 / 120\n",
      "2017-10-25 14:45:03.625668 combinations 3 : 50 / 120\n",
      "2017-10-25 14:45:03.860669 combinations 3 : 100 / 120\n",
      "2017-10-25 14:45:03.958665 combinations 4 : 0 / 210\n",
      "2017-10-25 14:45:04.217702 combinations 4 : 50 / 210\n",
      "2017-10-25 14:45:04.500701 combinations 4 : 100 / 210\n",
      "2017-10-25 14:45:04.805669 combinations 4 : 150 / 210\n",
      "2017-10-25 14:45:05.121667 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.9866666666666667\n",
      "3 1 Train Accuracy: 0.951694915254\n",
      "3 1 Test Accuracy: 0.922711864407\n",
      "2017-10-25 14:45:06.389665 combinations 2 : 0 / 45\n",
      "2017-10-25 14:45:06.567667 combinations 3 : 0 / 120\n",
      "2017-10-25 14:45:06.787667 combinations 3 : 50 / 120\n",
      "2017-10-25 14:45:07.023705 combinations 3 : 100 / 120\n",
      "2017-10-25 14:45:07.123702 combinations 4 : 0 / 210\n",
      "2017-10-25 14:45:07.388702 combinations 4 : 50 / 210\n",
      "2017-10-25 14:45:07.671667 combinations 4 : 100 / 210\n",
      "2017-10-25 14:45:07.971701 combinations 4 : 150 / 210\n",
      "2017-10-25 14:45:08.285702 combinations 4 : 200 / 210\n",
      "2017-10-25 14:45:08.560669 combinations 2 : 0 / 45\n",
      "2017-10-25 14:45:08.956702 combinations 3 : 0 / 120\n",
      "2017-10-25 14:45:09.436703 combinations 3 : 50 / 120\n",
      "2017-10-25 14:45:09.958708 combinations 3 : 100 / 120\n",
      "2017-10-25 14:45:10.175707 combinations 4 : 0 / 210\n",
      "2017-10-25 14:45:10.757666 combinations 4 : 50 / 210\n",
      "2017-10-25 14:45:11.375668 combinations 4 : 100 / 210\n",
      "2017-10-25 14:45:12.050665 combinations 4 : 150 / 210\n",
      "2017-10-25 14:45:12.751701 combinations 4 : 200 / 210\n",
      "Count: 250000\n",
      "Train Accuracy: 0.840983962573\n",
      "Test Accuracy: 0.836529189177\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize variables to submit data, this includes the id.\n",
    "It is important as the data will be separated depending on its features and category\n",
    "\"\"\"\n",
    "count = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "# For each category in PRI_num_jet and if they have or not NA\n",
    "for numjet in range(0, 4):\n",
    "    for index in range(0, 2):\n",
    "        # Get the x, y and ID\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        # Get the optimal weights and accuracy\n",
    "        w, predict_threshold, accuracy_train_k, accuracy_test_k = build_best_model(x_, y_, numjet, index)\n",
    "        \n",
    "        # Get the number of elements in that category\n",
    "        number_of_el = len(y_)\n",
    "\n",
    "        # Add the accuracy in proportion to the number of elements (max 1 if all elements in 1 category)\n",
    "        accuracy_train += accuracy_train_k * number_of_el\n",
    "        accuracy_test += accuracy_test_k * number_of_el\n",
    "        \n",
    "        # PRint training and testing accuracy\n",
    "        print(numjet, index, \"Train Accuracy: \" + str(accuracy_train_k))\n",
    "        print(numjet, index, \"Test Accuracy: \" + str(accuracy_test_k))\n",
    "        \n",
    "        # Count the number of elements\n",
    "        count += number_of_el\n",
    "  \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2, numjet, index)\n",
    "        pred_y2 = predict_labels(w, sub_x2, predict_threshold)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "        \n",
    "        sub_x = build_features(sub_x, numjet, index)\n",
    "        pred_y = predict_labels(w, sub_x, predict_threshold)\n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000 250000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84052000000000004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total accuracy in our train set\n",
    "def get_accuracy_ids(result_y, result_ids, y, ids):\n",
    "    stacked = np.column_stack((ids, y))\n",
    "    stacked = stacked[stacked[:,0].argsort()]\n",
    "    stacked_pred = np.column_stack((result_ids, result_y))\n",
    "    stacked_pred = stacked_pred[stacked_pred[:,0].argsort()]\n",
    "    \n",
    "    print(len(stacked_pred), len(stacked))\n",
    "    unique, counts = np.unique((stacked == stacked_pred)[:, 1], return_counts=True)\n",
    "    return dict(zip(unique, counts))[True] / len(y)\n",
    "\n",
    "get_accuracy_ids(result_y, result_ids, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created !\n"
     ]
    }
   ],
   "source": [
    "# Create submission csv file\n",
    "submission_stacked = np.column_stack((submission_ids, submission_y))\n",
    "submission_stacked = submission_stacked[submission_stacked[:,0].argsort()]\n",
    "create_csv_submission(submission_stacked[:,0], submission_stacked[:,1], \"datas/submission.csv\")\n",
    "print('Submission file created !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model for specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-25 14:10:11.854121 combinations 2 : 0 / 45\n",
      "2017-10-25 14:10:12.007120 combinations 3 : 0 / 120\n",
      "2017-10-25 14:10:12.197120 combinations 3 : 50 / 120\n",
      "2017-10-25 14:10:12.418121 combinations 3 : 100 / 120\n",
      "2017-10-25 14:10:12.546121 combinations 4 : 0 / 210\n",
      "2017-10-25 14:10:12.833124 combinations 4 : 50 / 210\n",
      "2017-10-25 14:10:13.146121 combinations 4 : 100 / 210\n",
      "2017-10-25 14:10:13.501120 combinations 4 : 150 / 210\n",
      "2017-10-25 14:10:13.916119 combinations 4 : 200 / 210\n",
      "2017-10-25 14:10:13.995121 combinations 5 : 0 / 252\n",
      "2017-10-25 14:10:14.419124 combinations 5 : 50 / 252\n",
      "2017-10-25 14:10:14.886119 combinations 5 : 100 / 252\n",
      "2017-10-25 14:10:15.478120 combinations 5 : 150 / 252\n",
      "2017-10-25 14:10:16.363121 combinations 5 : 200 / 252\n",
      "2017-10-25 14:10:17.261119 combinations 5 : 250 / 252\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "# Manually choose the categories\n",
    "x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, 2, 1)\n",
    "\n",
    "def build_polynomial2(x, max_degree):\n",
    "    polynomial_x = x\n",
    "    # Create new features with the tanh of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.tanh(x)), axis=1)\n",
    "    # Create new features with the ln of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.log(np.abs(x))), axis=1)\n",
    "    # Create new features with the square root of the original data\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x))), axis=1)\n",
    "    \n",
    "    # Create polynomials of max_degree of the new data\n",
    "    for degree in range(2, max_degree + 1):\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x, degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x), degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x)), degree)), axis=1)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "# Build combinations\n",
    "polynomial_x = normalize(x_)\n",
    "polynomial_x = build_polynomial(polynomial_x, 2)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "\n",
    "\n",
    "predict_threshold = -0.00\n",
    "\n",
    "# 4.52035365636e-07 0.813863667164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: 1e-08 Train: 0.960593220339  Test: 0.869491525424\n",
      "Lambdas: 1.88739182214e-08 Train: 0.960593220339  Test: 0.869491525424\n",
      "Lambdas: 3.56224789026e-08 Train: 0.960593220339  Test: 0.869152542373\n",
      "Lambdas: 6.7233575365e-08 Train: 0.960677966102  Test: 0.869152542373\n",
      "Lambdas: 1.26896100317e-07 Train: 0.960677966102  Test: 0.869491525424\n",
      "Lambdas: 2.39502661999e-07 Train: 0.960593220339  Test: 0.869830508475\n",
      "Lambdas: 4.52035365636e-07 Train: 0.960508474576  Test: 0.869491525424\n",
      "Lambdas: 8.53167852417e-07 Train: 0.960508474576  Test: 0.870169491525\n",
      "Lambdas: 1.61026202756e-06 Train: 0.960338983051  Test: 0.869491525424\n",
      "Lambdas: 3.03919538231e-06 Train: 0.960169491525  Test: 0.869152542373\n",
      "Lambdas: 5.73615251045e-06 Train: 0.959745762712  Test: 0.871525423729\n",
      "Lambdas: 1.08263673387e-05 Train: 0.959661016949  Test: 0.872881355932\n",
      "Lambdas: 2.04335971786e-05 Train: 0.95906779661  Test: 0.872542372881\n",
      "Lambdas: 3.85662042116e-05 Train: 0.958983050847  Test: 0.872881355932\n",
      "Lambdas: 7.27895384398e-05 Train: 0.957881355932  Test: 0.874237288136\n",
      "Lambdas: 0.000137382379588 Train: 0.957033898305  Test: 0.874237288136\n",
      "Lambdas: 0.00025929437974 Train: 0.955677966102  Test: 0.878644067797\n",
      "Lambdas: 0.000489390091848 Train: 0.954322033898  Test: 0.879661016949\n",
      "Lambdas: 0.000923670857187 Train: 0.953389830508  Test: 0.885762711864\n",
      "Lambdas: 0.0017433288222 Train: 0.951779661017  Test: 0.889152542373\n",
      "Lambdas: 0.00329034456231 Train: 0.949322033898  Test: 0.894237288136\n",
      "Lambdas: 0.00621016941892 Train: 0.946440677966  Test: 0.897966101695\n",
      "Lambdas: 0.0117210229753 Train: 0.943813559322  Test: 0.898983050847\n",
      "Lambdas: 0.0221221629107 Train: 0.941779661017  Test: 0.901694915254\n",
      "Lambdas: 0.0417531893656 Train: 0.938305084746  Test: 0.902372881356\n",
      "Lambdas: 0.0788046281567 Train: 0.93313559322  Test: 0.899322033898\n",
      "Lambdas: 0.148735210729 Train: 0.93093220339  Test: 0.901016949153\n",
      "Lambdas: 0.280721620394 Train: 0.924745762712  Test: 0.898983050847\n",
      "Lambdas: 0.529831690628 Train: 0.91813559322  Test: 0.898305084746\n",
      "Lambdas: 1.0 Train: 0.910677966102  Test: 0.894576271186\n",
      "\t Predicted -1 but was 1 : 0.8465608465608465\n",
      "BEST: 0.0417531893656 0.902372881356\n"
     ]
    }
   ],
   "source": [
    "# Here to test the accuracy of one specific classifier\n",
    "# Find best lambdas\n",
    "lambdas = np.logspace(-8, 0, 30)\n",
    "best_accuracy = 0\n",
    "best_lambda = 0\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_lambda = lambda_\n",
    "    print(\"Lambdas:\", lambda_, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_lambda, best_accuracy)\n",
    "lambda_ = best_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh: 0.0 Train: 0.938305084746  Test: 0.902372881356\n",
      "Thresh: -0.0040404040404 Train: 0.938728813559  Test: 0.902372881356\n",
      "Thresh: -0.00808080808081 Train: 0.938728813559  Test: 0.903389830508\n",
      "Thresh: -0.0121212121212 Train: 0.938728813559  Test: 0.903050847458\n",
      "Thresh: -0.0161616161616 Train: 0.938898305085  Test: 0.903050847458\n",
      "Thresh: -0.020202020202 Train: 0.938898305085  Test: 0.903050847458\n",
      "Thresh: -0.0242424242424 Train: 0.938983050847  Test: 0.903050847458\n",
      "Thresh: -0.0282828282828 Train: 0.939237288136  Test: 0.90406779661\n",
      "Thresh: -0.0323232323232 Train: 0.939491525424  Test: 0.904406779661\n",
      "Thresh: -0.0363636363636 Train: 0.939830508475  Test: 0.904406779661\n",
      "Thresh: -0.040404040404 Train: 0.94  Test: 0.90406779661\n",
      "Thresh: -0.0444444444444 Train: 0.939915254237  Test: 0.903389830508\n",
      "Thresh: -0.0484848484848 Train: 0.940084745763  Test: 0.902372881356\n",
      "Thresh: -0.0525252525253 Train: 0.940338983051  Test: 0.902711864407\n",
      "Thresh: -0.0565656565657 Train: 0.939745762712  Test: 0.902711864407\n",
      "Thresh: -0.0606060606061 Train: 0.939745762712  Test: 0.902372881356\n",
      "Thresh: -0.0646464646465 Train: 0.940084745763  Test: 0.902033898305\n",
      "Thresh: -0.0686868686869 Train: 0.939915254237  Test: 0.901355932203\n",
      "Thresh: -0.0727272727273 Train: 0.940423728814  Test: 0.901355932203\n",
      "Thresh: -0.0767676767677 Train: 0.940423728814  Test: 0.901355932203\n",
      "Thresh: -0.0808080808081 Train: 0.940593220339  Test: 0.901694915254\n",
      "Thresh: -0.0848484848485 Train: 0.940677966102  Test: 0.902372881356\n",
      "Thresh: -0.0888888888889 Train: 0.940593220339  Test: 0.902372881356\n",
      "Thresh: -0.0929292929293 Train: 0.940423728814  Test: 0.902372881356\n",
      "Thresh: -0.0969696969697 Train: 0.940508474576  Test: 0.902372881356\n",
      "Thresh: -0.10101010101 Train: 0.940423728814  Test: 0.901355932203\n",
      "Thresh: -0.105050505051 Train: 0.940423728814  Test: 0.901355932203\n",
      "Thresh: -0.109090909091 Train: 0.940338983051  Test: 0.901355932203\n",
      "Thresh: -0.113131313131 Train: 0.940508474576  Test: 0.901694915254\n",
      "Thresh: -0.117171717172 Train: 0.940423728814  Test: 0.900677966102\n",
      "Thresh: -0.121212121212 Train: 0.940423728814  Test: 0.900677966102\n",
      "Thresh: -0.125252525253 Train: 0.940423728814  Test: 0.901016949153\n",
      "Thresh: -0.129292929293 Train: 0.940169491525  Test: 0.901016949153\n",
      "Thresh: -0.133333333333 Train: 0.940338983051  Test: 0.900338983051\n",
      "Thresh: -0.137373737374 Train: 0.940084745763  Test: 0.900338983051\n",
      "Thresh: -0.141414141414 Train: 0.94  Test: 0.900338983051\n",
      "Thresh: -0.145454545455 Train: 0.94  Test: 0.900338983051\n",
      "Thresh: -0.149494949495 Train: 0.939830508475  Test: 0.9\n",
      "Thresh: -0.153535353535 Train: 0.939830508475  Test: 0.899322033898\n",
      "Thresh: -0.157575757576 Train: 0.939745762712  Test: 0.899661016949\n",
      "Thresh: -0.161616161616 Train: 0.939406779661  Test: 0.899322033898\n",
      "Thresh: -0.165656565657 Train: 0.939322033898  Test: 0.898983050847\n",
      "Thresh: -0.169696969697 Train: 0.939152542373  Test: 0.898983050847\n",
      "Thresh: -0.173737373737 Train: 0.93906779661  Test: 0.898305084746\n",
      "Thresh: -0.177777777778 Train: 0.939152542373  Test: 0.897966101695\n",
      "Thresh: -0.181818181818 Train: 0.93906779661  Test: 0.898305084746\n",
      "Thresh: -0.185858585859 Train: 0.938813559322  Test: 0.898305084746\n",
      "Thresh: -0.189898989899 Train: 0.938983050847  Test: 0.897966101695\n",
      "Thresh: -0.193939393939 Train: 0.938813559322  Test: 0.897966101695\n",
      "Thresh: -0.19797979798 Train: 0.938898305085  Test: 0.897966101695\n",
      "Thresh: -0.20202020202 Train: 0.938305084746  Test: 0.897627118644\n",
      "Thresh: -0.206060606061 Train: 0.938220338983  Test: 0.897966101695\n",
      "Thresh: -0.210101010101 Train: 0.938220338983  Test: 0.897627118644\n",
      "Thresh: -0.214141414141 Train: 0.938305084746  Test: 0.897627118644\n",
      "Thresh: -0.218181818182 Train: 0.938389830508  Test: 0.897627118644\n",
      "Thresh: -0.222222222222 Train: 0.938389830508  Test: 0.896949152542\n",
      "Thresh: -0.226262626263 Train: 0.938389830508  Test: 0.896949152542\n",
      "Thresh: -0.230303030303 Train: 0.938644067797  Test: 0.896949152542\n",
      "Thresh: -0.234343434343 Train: 0.938813559322  Test: 0.896949152542\n",
      "Thresh: -0.238383838384 Train: 0.938813559322  Test: 0.897966101695\n",
      "Thresh: -0.242424242424 Train: 0.938898305085  Test: 0.897966101695\n",
      "Thresh: -0.246464646465 Train: 0.938813559322  Test: 0.898305084746\n",
      "Thresh: -0.250505050505 Train: 0.938644067797  Test: 0.898305084746\n",
      "Thresh: -0.254545454545 Train: 0.938644067797  Test: 0.898305084746\n",
      "Thresh: -0.258585858586 Train: 0.938644067797  Test: 0.898644067797\n",
      "Thresh: -0.262626262626 Train: 0.938898305085  Test: 0.898305084746\n",
      "Thresh: -0.266666666667 Train: 0.938644067797  Test: 0.897966101695\n",
      "Thresh: -0.270707070707 Train: 0.938728813559  Test: 0.897966101695\n",
      "Thresh: -0.274747474747 Train: 0.938559322034  Test: 0.897627118644\n",
      "Thresh: -0.278787878788 Train: 0.938559322034  Test: 0.897288135593\n",
      "Thresh: -0.282828282828 Train: 0.938644067797  Test: 0.897288135593\n",
      "Thresh: -0.286868686869 Train: 0.938644067797  Test: 0.897288135593\n",
      "Thresh: -0.290909090909 Train: 0.938474576271  Test: 0.896949152542\n",
      "Thresh: -0.294949494949 Train: 0.937966101695  Test: 0.896610169492\n",
      "Thresh: -0.29898989899 Train: 0.937881355932  Test: 0.896610169492\n",
      "Thresh: -0.30303030303 Train: 0.937881355932  Test: 0.896271186441\n",
      "Thresh: -0.307070707071 Train: 0.938050847458  Test: 0.89593220339\n",
      "Thresh: -0.311111111111 Train: 0.93813559322  Test: 0.895593220339\n",
      "Thresh: -0.315151515152 Train: 0.938050847458  Test: 0.895254237288\n",
      "Thresh: -0.319191919192 Train: 0.93813559322  Test: 0.894915254237\n",
      "Thresh: -0.323232323232 Train: 0.938305084746  Test: 0.894576271186\n",
      "Thresh: -0.327272727273 Train: 0.938474576271  Test: 0.895254237288\n",
      "Thresh: -0.331313131313 Train: 0.93813559322  Test: 0.893898305085\n",
      "Thresh: -0.335353535354 Train: 0.938220338983  Test: 0.894237288136\n",
      "Thresh: -0.339393939394 Train: 0.938220338983  Test: 0.894237288136\n",
      "Thresh: -0.343434343434 Train: 0.938305084746  Test: 0.893559322034\n",
      "Thresh: -0.347474747475 Train: 0.937711864407  Test: 0.893559322034\n",
      "Thresh: -0.351515151515 Train: 0.937457627119  Test: 0.892542372881\n",
      "Thresh: -0.355555555556 Train: 0.93686440678  Test: 0.89186440678\n",
      "Thresh: -0.359595959596 Train: 0.936694915254  Test: 0.891525423729\n",
      "Thresh: -0.363636363636 Train: 0.936525423729  Test: 0.891525423729\n",
      "Thresh: -0.367676767677 Train: 0.936101694915  Test: 0.891525423729\n",
      "Thresh: -0.371717171717 Train: 0.936101694915  Test: 0.891525423729\n",
      "Thresh: -0.375757575758 Train: 0.935762711864  Test: 0.890508474576\n",
      "Thresh: -0.379797979798 Train: 0.935508474576  Test: 0.890169491525\n",
      "Thresh: -0.383838383838 Train: 0.935762711864  Test: 0.890169491525\n",
      "Thresh: -0.387878787879 Train: 0.93593220339  Test: 0.890508474576\n",
      "Thresh: -0.391919191919 Train: 0.935677966102  Test: 0.890508474576\n",
      "Thresh: -0.39595959596 Train: 0.935423728814  Test: 0.890847457627\n",
      "Thresh: -0.4 Train: 0.935169491525  Test: 0.889491525424\n",
      "\t Predicted -1 but was 1 : 0.4623115577889447\n",
      "BEST: -0.0323232323232 0.904406779661\n"
     ]
    }
   ],
   "source": [
    "# Find best threshold\n",
    "threshs = np.linspace(0, -0.4, num=100)\n",
    "best_accuracy = 0\n",
    "best_thresh = 0\n",
    "for thresh in threshs:\n",
    "    predict_threshold = thresh\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_thresh = thresh\n",
    "    print(\"Thresh:\", thresh, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_thresh, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
