{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "from features_engineering import *\n",
    "from cross_validation import *\n",
    "from pre_processing import *\n",
    "from group_by import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (227458, 30) (227458,) (227458,)\n",
      "1 (175338, 30) (175338,) (175338,)\n",
      "2 (114648, 30) (114648,) (114648,)\n",
      "3 (50794, 30) (50794,) (50794,)\n",
      "num_jet: 0\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (59263, 19) (59263, 1) (59263, 1)\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (168195, 20) (168195, 1) (168195, 1)\n",
      "\tRemove col : \n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (158095, 23) (158095, 1) (158095, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (17243, 22) (17243, 1) (17243, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (107905, 30) (107905, 1) (107905, 1)\n",
      "(0,) (6743, 29) (6743, 1) (6743, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (47555, 30) (47555, 1) (47555, 1)\n",
      "(0,) (3239, 29) (3239, 1) (3239, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "sub_jet_num_x_dict, sub_jet_num_y_dict, sub_jet_num_ids_dict = group_by_jetnum_NaN(submission_x, submission_y, submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (99913, 30) (99913,) (99913,)\n",
      "1 (77544, 30) (77544,) (77544,)\n",
      "2 (50379, 30) (50379,) (50379,)\n",
      "3 (22164, 30) (22164,) (22164,)\n",
      "num_jet: 0\n",
      "(4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (73790, 20) (73790, 1) (73790, 1)\n",
      "(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) (26123, 19) (26123, 1) (26123, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 19 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 17 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "\t (0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28) 18 [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "num_jet: 1\n",
      "(4, 5, 6, 12, 26, 27, 28) (69982, 23) (69982, 1) (69982, 1)\n",
      "(0, 4, 5, 6, 12, 26, 27, 28) (7562, 22) (7562, 1) (7562, 1)\n",
      "\tRemove col : \n",
      "\t (4, 5, 6, 12, 26, 27, 28) 18 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "\t (0, 4, 5, 6, 12, 26, 27, 28) 17 [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "num_jet: 2\n",
      "() (47427, 30) (47427, 1) (47427, 1)\n",
      "(0,) (2952, 29) (2952, 1) (2952, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "\t (0,) 21 [ 2.  2.  2. ...,  2.  2.  2.]\n",
      "num_jet: 3\n",
      "() (20687, 30) (20687, 1) (20687, 1)\n",
      "(0,) (1477, 29) (1477, 1) (1477, 1)\n",
      "\tRemove col : \n",
      "\t () 22 [ 3.  3.  3. ...,  3.  3.  3.]\n",
      "\t (0,) 21 [ 3.  3.  3. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict = group_by_jetnum_NaN(x, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea : Unbalance data\n",
    "# Check misclassified data\n",
    "\n",
    "# Need to test on two group of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(submission_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, x2, _ = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "print(proportion_of_NaN(x2) - proportion_of_NaN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportion_of_NaN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_init = np.random.rand(x.shape[1])\n",
    "w, loss = least_squares_GD(train_y, train_x, w_init, max_iters=100, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(train_y, train_x, w_init, 100, gamma=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(test_x, test_y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, submission_x, submission_ids = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "submission_x = submission_x[:, :15] # Removed all the primary\n",
    "submission_x = preprocess_data(submission_x)\n",
    "\n",
    "submission_x = build_polynomial(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 2)\n",
    "submission_x = build_combinations_lvl(submission_x, 3)\n",
    "submission_x = build_combinations_lvl(submission_x, 4)\n",
    "submission_x = build_combinations_lvl(submission_x, 5)\n",
    "submission_x = build_combinations_lvl(submission_x, 6)\n",
    "submission_x = build_combinations_lvl(submission_x, 7)\n",
    "submission_x = build_combinations_lvl(submission_x, 8)\n",
    "\n",
    "pred_y = predict_labels(w, submission_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(submission_ids, submission_y, \"datas/submission.csv\")\n",
    "print('Done !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/a/7941594/4810319\n",
    "def main():\n",
    "    np.random.seed(1977)\n",
    "    numvars, numdata = 5, 100\n",
    "    data = 10 * np.random.random((numvars, numdata))\n",
    "    data = x[0:300, 0:7].T\n",
    "    print(x[0:200, 7])\n",
    "    fig = scatterplot_matrix(data, ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet'],\n",
    "            linestyle='none', marker='o', color='black', mfc='none')\n",
    "    fig.suptitle('Simple Scatterplot Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def scatterplot_matrix(data, names, **kwargs):\n",
    "    \"\"\"Plots a scatterplot matrix of subplots.  Each row of \"data\" is plotted\n",
    "    against other rows, resulting in a nrows by nrows grid of subplots with the\n",
    "    diagonal subplots labeled with \"names\".  Additional keyword arguments are\n",
    "    passed on to matplotlib's \"plot\" command. Returns the matplotlib figure\n",
    "    object containg the subplot grid.\"\"\"\n",
    "    numvars, numdata = data.shape\n",
    "    fig, axes = plt.subplots(nrows=numvars, ncols=numvars, figsize=(8,8))\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        # Hide all ticks and labels\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "        # Set up ticks only on one side for the \"edge\" subplots...\n",
    "        if ax.is_first_col():\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "        if ax.is_last_col():\n",
    "            ax.yaxis.set_ticks_position('right')\n",
    "        if ax.is_first_row():\n",
    "            ax.xaxis.set_ticks_position('top')\n",
    "        if ax.is_last_row():\n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    # Plot the data.\n",
    "    for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "        for x, y in [(i,j), (j,i)]:\n",
    "            axes[x,y].plot(data[x], data[y], **kwargs)\n",
    "\n",
    "    # Label the diagonal subplots...\n",
    "    for i, label in enumerate(names):\n",
    "        axes[i,i].annotate(label, (0.5, 0.5), xycoords='axes fraction',\n",
    "                ha='center', va='center')\n",
    "\n",
    "    # Turn on the proper x or y axes ticks.\n",
    "    for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n",
    "        axes[j,i].xaxis.set_visible(True)\n",
    "        axes[i,j].yaxis.set_visible(True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering (Add more features)\n",
    "polynomial_x = x\n",
    "# polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 2)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 3)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 4)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 5)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 6)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 7)\n",
    "# polynomial_x = build_combinations_lvl(polynomial_x, 8)\n",
    "\n",
    "train_x, train_y, test_x, test_y = separate_set(polynomial_x, y)\n",
    "\n",
    "polynomial_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000 250000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84077999999999997"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_ids(result_y, result_ids, y, ids):\n",
    "    stacked = np.column_stack((ids, y))\n",
    "    stacked = stacked[stacked[:,0].argsort()]\n",
    "    stacked_pred = np.column_stack((result_ids, result_y))\n",
    "    stacked_pred = stacked_pred[stacked_pred[:,0].argsort()]\n",
    "    \n",
    "    print(len(stacked_pred), len(stacked))\n",
    "    unique, counts = np.unique((stacked == stacked_pred)[:, 1], return_counts=True)\n",
    "    return dict(zip(unique, counts))[True] / len(y)\n",
    "\n",
    "get_accuracy_ids(result_y, result_ids, y, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_stacked = np.column_stack((submission_ids, submission_y))\n",
    "submission_stacked = submission_stacked[submission_stacked[:,0].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "create_csv_submission(submission_stacked[:,0], submission_stacked[:,1], \"datas/submission.csv\")\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed=1):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def k_fold_cross_validation(y, x, k, lambda_, predict_threshold=0):\n",
    "    \"\"\"return the accuracy of ridge regression.\"\"\"\n",
    "    \n",
    "    k_indices = build_k_indices(y, k)\n",
    "    accuracy_tr = []\n",
    "    accuracy_te = []\n",
    "    \n",
    "    accuracy_tr = []\n",
    "    accuracy_te = []\n",
    "\n",
    "    for i in range(0, k):\n",
    "        i = 0\n",
    "        \n",
    "        # get k'th subgroup in test, others in train:\n",
    "        x_test = x[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        x_train = np.array([]).reshape(0, x.shape[1])\n",
    "        y_train = np.array([]).reshape(0, 1)\n",
    "\n",
    "        for j in range(0, k):\n",
    "            if j != i:\n",
    "                x_train = np.concatenate((x_train, x[k_indices[j]]))\n",
    "                y_train = np.concatenate((y_train, y[k_indices[j]]))\n",
    "\n",
    "        # ridge regression:\n",
    "        w, loss = ridge_regression(y_train, x_train, lambda_)\n",
    "\n",
    "        # calculate the loss for train and test data\n",
    "        accuracy_tr.append(get_accuracy(x_train, y_train, w, predict_threshold))\n",
    "        accuracy_te.append(get_accuracy(x_test, y_test, w, predict_threshold))\n",
    "\n",
    "    return np.mean(accuracy_tr), np.mean(accuracy_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "lambda_ = 0.0001\n",
    "k_fold_cross_validation(y, x, k, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "lambdas = np.logspace(-4, 0, 15)\n",
    "x_features = build_features(x)\n",
    "for lambda_ in lambdas:\n",
    "    loss_tr, loss_te = k_fold_cross_validation(y, x_features, 4, lambda_)\n",
    "    rmse_tr += [loss_tr] \n",
    "    rmse_te += [loss_te]\n",
    "cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.00001\n",
    "train_x, train_y, test_x, test_y = separate_set(x, y)\n",
    "w, loss = ridge_regression(train_y, train_x, lambda_)\n",
    "get_accuracy(test_x, test_y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false(x, y, w, predict_threshold):\n",
    "    pred_y = predict_labels(w, x, predict_threshold)\n",
    "    false_count = 0\n",
    "    count_negatif = 0\n",
    "    for index, yi in enumerate(y):\n",
    "        pred_yi = pred_y[index]\n",
    "        if pred_yi != yi:\n",
    "            false_count += 1\n",
    "            if pred_yi == -1:\n",
    "                count_negatif += 1\n",
    "    \n",
    "    return count_negatif / false_count\n",
    "\n",
    "\n",
    "\n",
    "def get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index):\n",
    "    removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "    x = jet_num_x_dict[numjet][removed_col_key]\n",
    "    y = jet_num_y_dict[numjet][removed_col_key]\n",
    "    ids = jet_num_ids_dict[numjet][removed_col_key]\n",
    "    return x, y, ids\n",
    "\n",
    "def build_features(x, numjet, index):\n",
    "    if numjet == 0 and index == 0:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "    elif numjet == 1 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 2 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 2)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "    elif numjet == 3 and index == 1:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 6)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "    else:\n",
    "        polynomial_x = normalize(x)\n",
    "        polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "        polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "def build_best_model(x_, y_, numjet, index):\n",
    "    k = 5\n",
    "    predict_threshold = 0\n",
    "    polynomial_x = build_features(x_, numjet, index)\n",
    "\n",
    "    if numjet == 0 and index == 0:\n",
    "        lambda_ = 0.000001\n",
    "    elif numjet == 1 and index == 1:\n",
    "        lambda_ = 0.137382379588\n",
    "    elif numjet == 2 and index == 1:\n",
    "        lambda_ = 0.0188739182214\n",
    "    elif numjet == 3 and index == 1:\n",
    "        predict_threshold = -0.1\n",
    "        lambda_ = 0.5\n",
    "    else:\n",
    "        lambda_ = 0.000001\n",
    "\n",
    "\n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "    w, loss = ridge_regression(y_, polynomial_x, lambda_)\n",
    "\n",
    "    \n",
    "    print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "    \n",
    "    return w, predict_threshold, accuracy_train_k, accuracy_test_k\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-14 11:46:05.121233 combinations 2 : 0 / 45\n",
      "2017-10-14 11:46:08.921240 combinations 3 : 0 / 120\n",
      "2017-10-14 11:46:13.577232 combinations 3 : 50 / 120\n",
      "2017-10-14 11:46:19.137233 combinations 3 : 100 / 120\n",
      "2017-10-14 11:46:21.689273 combinations 4 : 0 / 210\n",
      "2017-10-14 11:46:31.331235 combinations 4 : 50 / 210\n",
      "2017-10-14 11:46:39.487236 combinations 4 : 100 / 210\n",
      "2017-10-14 11:46:48.688687 combinations 4 : 150 / 210\n",
      "2017-10-14 11:46:58.811711 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.6353822427847543\n",
      "0 0 Train Accuracy: 0.81626914216\n",
      "0 0 Test Accuracy: 0.813253828432\n",
      "2017-10-14 11:47:25.632709 combinations 2 : 0 / 45\n",
      "2017-10-14 11:47:29.793714 combinations 3 : 0 / 120\n",
      "2017-10-14 11:47:36.198263 combinations 3 : 50 / 120\n",
      "2017-10-14 11:47:43.614711 combinations 3 : 100 / 120\n",
      "2017-10-14 11:47:46.753245 combinations 4 : 0 / 210\n",
      "2017-10-14 11:47:54.977789 combinations 4 : 50 / 210\n",
      "2017-10-14 11:48:03.294400 combinations 4 : 100 / 210\n",
      "2017-10-14 11:48:12.512397 combinations 4 : 150 / 210\n",
      "2017-10-14 11:48:22.196398 combinations 4 : 200 / 210\n",
      "2017-10-14 11:48:26.604403 combinations 2 : 0 / 45\n",
      "2017-10-14 11:48:34.403437 combinations 3 : 0 / 120\n",
      "2017-10-14 11:48:45.791989 combinations 3 : 50 / 120\n",
      "2017-10-14 11:49:01.035519 combinations 3 : 100 / 120\n",
      "2017-10-14 11:49:07.063518 combinations 4 : 0 / 210\n",
      "2017-10-14 11:49:24.254520 combinations 4 : 50 / 210\n",
      "2017-10-14 11:49:43.825527 combinations 4 : 100 / 210\n",
      "2017-10-14 11:50:06.324482 combinations 4 : 150 / 210\n",
      "2017-10-14 11:50:33.897491 combinations 4 : 200 / 210\n",
      "2017-10-14 11:50:40.646518 combinations 2 : 0 / 45\n",
      "2017-10-14 11:50:42.417493 combinations 3 : 0 / 120\n",
      "2017-10-14 11:50:44.728485 combinations 3 : 50 / 120\n",
      "2017-10-14 11:50:47.376178 combinations 3 : 100 / 120\n",
      "2017-10-14 11:50:48.730639 combinations 4 : 0 / 210\n",
      "2017-10-14 11:50:51.867894 combinations 4 : 50 / 210\n",
      "2017-10-14 11:50:55.102453 combinations 4 : 100 / 210\n",
      "2017-10-14 11:50:59.148024 combinations 4 : 150 / 210\n",
      "2017-10-14 11:51:02.875782 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.9390739236393176\n",
      "0 1 Train Accuracy: 0.953101071975\n",
      "0 1 Test Accuracy: 0.949846860643\n",
      "2017-10-14 11:51:11.379751 combinations 2 : 0 / 45\n",
      "2017-10-14 11:51:12.554782 combinations 3 : 0 / 120\n",
      "2017-10-14 11:51:14.086743 combinations 3 : 50 / 120\n",
      "2017-10-14 11:51:16.115744 combinations 3 : 100 / 120\n",
      "2017-10-14 11:51:17.060747 combinations 4 : 0 / 210\n",
      "2017-10-14 11:51:19.716747 combinations 4 : 50 / 210\n",
      "2017-10-14 11:51:22.450744 combinations 4 : 100 / 210\n",
      "2017-10-14 11:51:25.809746 combinations 4 : 150 / 210\n",
      "2017-10-14 11:51:29.426748 combinations 4 : 200 / 210\n",
      "2017-10-14 11:51:31.223747 combinations 2 : 0 / 45\n",
      "2017-10-14 11:51:33.922748 combinations 3 : 0 / 120\n",
      "2017-10-14 11:51:37.575746 combinations 3 : 50 / 120\n",
      "2017-10-14 11:51:42.214746 combinations 3 : 100 / 120\n",
      "2017-10-14 11:51:44.114748 combinations 4 : 0 / 210\n",
      "2017-10-14 11:51:50.009766 combinations 4 : 50 / 210\n",
      "2017-10-14 11:51:56.191860 combinations 4 : 100 / 210\n",
      "2017-10-14 11:52:03.393725 combinations 4 : 150 / 210\n",
      "2017-10-14 11:52:12.186739 combinations 4 : 200 / 210\n",
      "2017-10-14 11:52:16.117731 combinations 2 : 0 / 45\n",
      "2017-10-14 11:52:22.266733 combinations 3 : 0 / 120\n",
      "2017-10-14 11:52:29.768732 combinations 3 : 50 / 120\n",
      "2017-10-14 11:52:40.648704 combinations 3 : 100 / 120\n",
      "2017-10-14 11:52:44.837708 combinations 4 : 0 / 210\n",
      "2017-10-14 11:52:54.932888 combinations 4 : 50 / 210\n",
      "2017-10-14 11:53:07.594189 combinations 4 : 100 / 210\n",
      "2017-10-14 11:53:26.649695 combinations 4 : 150 / 210\n",
      "2017-10-14 11:53:50.670695 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.5616155660377359\n",
      "1 0 Train Accuracy: 0.807480708774\n",
      "1 0 Test Accuracy: 0.800371534724\n",
      "2017-10-14 11:54:18.659165 combinations 2 : 0 / 45\n",
      "2017-10-14 11:54:24.736281 combinations 3 : 0 / 120\n",
      "2017-10-14 11:54:30.652243 combinations 3 : 50 / 120\n",
      "2017-10-14 11:54:37.177242 combinations 3 : 100 / 120\n",
      "2017-10-14 11:54:40.062273 combinations 4 : 0 / 210\n",
      "2017-10-14 11:54:48.791267 combinations 4 : 50 / 210\n",
      "2017-10-14 11:54:57.542116 combinations 4 : 100 / 210\n",
      "2017-10-14 11:55:07.931497 combinations 4 : 150 / 210\n",
      "2017-10-14 11:55:20.653115 combinations 4 : 200 / 210\n",
      "2017-10-14 11:55:25.704116 combinations 2 : 0 / 45\n",
      "2017-10-14 11:55:34.845118 combinations 3 : 0 / 120\n",
      "2017-10-14 11:55:46.652156 combinations 3 : 50 / 120\n",
      "2017-10-14 11:56:03.329655 combinations 3 : 100 / 120\n",
      "2017-10-14 11:56:11.229161 combinations 4 : 0 / 210\n",
      "2017-10-14 11:56:30.779175 combinations 4 : 50 / 210\n",
      "2017-10-14 11:56:49.374140 combinations 4 : 100 / 210\n",
      "2017-10-14 11:57:15.492828 combinations 4 : 150 / 210\n",
      "2017-10-14 11:57:40.880830 combinations 4 : 200 / 210\n",
      "2017-10-14 11:57:45.595837 combinations 2 : 0 / 45\n",
      "2017-10-14 11:57:46.016832 combinations 3 : 0 / 120\n",
      "2017-10-14 11:57:46.535833 combinations 3 : 50 / 120\n",
      "2017-10-14 11:57:47.152835 combinations 3 : 100 / 120\n",
      "2017-10-14 11:57:47.422870 combinations 4 : 0 / 210\n",
      "2017-10-14 11:57:48.175833 combinations 4 : 50 / 210\n",
      "2017-10-14 11:57:48.992832 combinations 4 : 100 / 210\n",
      "2017-10-14 11:57:49.912838 combinations 4 : 150 / 210\n",
      "2017-10-14 11:57:51.012832 combinations 4 : 200 / 210\n",
      "2017-10-14 11:57:51.259868 combinations 5 : 0 / 252\n",
      "2017-10-14 11:57:52.398832 combinations 5 : 50 / 252\n",
      "2017-10-14 11:57:53.645836 combinations 5 : 100 / 252\n",
      "2017-10-14 11:57:55.026838 combinations 5 : 150 / 252\n",
      "2017-10-14 11:57:56.635833 combinations 5 : 200 / 252\n",
      "2017-10-14 11:57:58.443735 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.9713740458015268\n",
      "1 1 Train Accuracy: 0.930555555556\n",
      "1 1 Test Accuracy: 0.920634920635\n",
      "2017-10-14 11:58:02.110757 combinations 2 : 0 / 45\n",
      "2017-10-14 11:58:02.576263 combinations 3 : 0 / 120\n",
      "2017-10-14 11:58:03.229762 combinations 3 : 50 / 120\n",
      "2017-10-14 11:58:04.080261 combinations 3 : 100 / 120\n",
      "2017-10-14 11:58:04.448261 combinations 4 : 0 / 210\n",
      "2017-10-14 11:58:05.550758 combinations 4 : 50 / 210\n",
      "2017-10-14 11:58:06.507760 combinations 4 : 100 / 210\n",
      "2017-10-14 11:58:07.660260 combinations 4 : 150 / 210\n",
      "2017-10-14 11:58:08.891635 combinations 4 : 200 / 210\n",
      "2017-10-14 11:58:09.248779 combinations 5 : 0 / 252\n",
      "2017-10-14 11:58:10.933081 combinations 5 : 50 / 252\n",
      "2017-10-14 11:58:12.449611 combinations 5 : 100 / 252\n",
      "2017-10-14 11:58:13.891675 combinations 5 : 150 / 252\n",
      "2017-10-14 11:58:15.850711 combinations 5 : 200 / 252\n",
      "2017-10-14 11:58:17.660677 combinations 5 : 250 / 252\n",
      "2017-10-14 11:58:18.597676 combinations 2 : 0 / 45\n",
      "2017-10-14 11:58:19.790714 combinations 3 : 0 / 120\n",
      "2017-10-14 11:58:21.397676 combinations 3 : 50 / 120\n",
      "2017-10-14 11:58:22.844676 combinations 3 : 100 / 120\n",
      "2017-10-14 11:58:23.561678 combinations 4 : 0 / 210\n",
      "2017-10-14 11:58:25.291676 combinations 4 : 50 / 210\n",
      "2017-10-14 11:58:27.236677 combinations 4 : 100 / 210\n",
      "2017-10-14 11:58:29.371680 combinations 4 : 150 / 210\n",
      "2017-10-14 11:58:31.721715 combinations 4 : 200 / 210\n",
      "2017-10-14 11:58:32.253683 combinations 5 : 0 / 252\n",
      "2017-10-14 11:58:34.821717 combinations 5 : 50 / 252\n",
      "2017-10-14 11:58:37.688677 combinations 5 : 100 / 252\n",
      "2017-10-14 11:58:40.698681 combinations 5 : 150 / 252\n",
      "2017-10-14 11:58:43.883682 combinations 5 : 200 / 252\n",
      "2017-10-14 11:58:47.699682 combinations 5 : 250 / 252\n",
      "2017-10-14 11:58:49.028684 combinations 2 : 0 / 45\n",
      "2017-10-14 11:58:52.395680 combinations 3 : 0 / 120\n",
      "2017-10-14 11:58:56.956679 combinations 3 : 50 / 120\n",
      "2017-10-14 11:59:04.063353 combinations 3 : 100 / 120\n",
      "2017-10-14 11:59:06.489850 combinations 4 : 0 / 210\n",
      "2017-10-14 11:59:13.073532 combinations 4 : 50 / 210\n",
      "2017-10-14 11:59:21.521788 combinations 4 : 100 / 210\n",
      "2017-10-14 11:59:29.508789 combinations 4 : 150 / 210\n",
      "2017-10-14 11:59:38.713792 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.4613196043896491\n",
      "2 0 Train Accuracy: 0.845730100158\n",
      "2 0 Test Accuracy: 0.837638376384\n",
      "2017-10-14 12:00:00.889795 combinations 2 : 0 / 45\n",
      "2017-10-14 12:00:04.373202 combinations 3 : 0 / 120\n",
      "2017-10-14 12:00:08.788646 combinations 3 : 50 / 120\n",
      "2017-10-14 12:00:14.412837 combinations 3 : 100 / 120\n",
      "2017-10-14 12:00:16.680247 combinations 4 : 0 / 210\n",
      "2017-10-14 12:00:22.859250 combinations 4 : 50 / 210\n",
      "2017-10-14 12:00:29.984251 combinations 4 : 100 / 210\n",
      "2017-10-14 12:00:37.208288 combinations 4 : 150 / 210\n",
      "2017-10-14 12:00:46.156250 combinations 4 : 200 / 210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-14 12:00:50.727488 combinations 2 : 0 / 45\n",
      "2017-10-14 12:00:59.850455 combinations 3 : 0 / 120\n",
      "2017-10-14 12:01:11.146144 combinations 3 : 50 / 120\n",
      "2017-10-14 12:01:23.575288 combinations 3 : 100 / 120\n",
      "2017-10-14 12:01:28.443321 combinations 4 : 0 / 210\n",
      "2017-10-14 12:01:41.782285 combinations 4 : 50 / 210\n",
      "2017-10-14 12:01:58.953287 combinations 4 : 100 / 210\n",
      "2017-10-14 12:02:15.289807 combinations 4 : 150 / 210\n",
      "2017-10-14 12:02:35.342312 combinations 4 : 200 / 210\n",
      "2017-10-14 12:02:39.997528 combinations 2 : 0 / 45\n",
      "2017-10-14 12:02:40.197030 combinations 3 : 0 / 120\n",
      "2017-10-14 12:02:40.470031 combinations 3 : 50 / 120\n",
      "2017-10-14 12:02:40.850033 combinations 3 : 100 / 120\n",
      "2017-10-14 12:02:40.980530 combinations 4 : 0 / 210\n",
      "2017-10-14 12:02:41.263529 combinations 4 : 50 / 210\n",
      "2017-10-14 12:02:41.625529 combinations 4 : 100 / 210\n",
      "2017-10-14 12:02:41.993030 combinations 4 : 150 / 210\n",
      "2017-10-14 12:02:42.483566 combinations 4 : 200 / 210\n",
      "2017-10-14 12:02:42.565100 combinations 5 : 0 / 252\n",
      "2017-10-14 12:02:42.979065 combinations 5 : 50 / 252\n",
      "2017-10-14 12:02:43.448755 combinations 5 : 100 / 252\n",
      "2017-10-14 12:02:43.950268 combinations 5 : 150 / 252\n",
      "2017-10-14 12:02:44.502313 combinations 5 : 200 / 252\n",
      "2017-10-14 12:02:45.181816 combinations 5 : 250 / 252\n",
      "\t Predicted -1 but was 1 : 0.8285714285714286\n",
      "2 1 Train Accuracy: 0.940254237288\n",
      "2 1 Test Accuracy: 0.910169491525\n",
      "2017-10-14 12:02:46.796361 combinations 2 : 0 / 45\n",
      "2017-10-14 12:02:47.006361 combinations 3 : 0 / 120\n",
      "2017-10-14 12:02:47.277366 combinations 3 : 50 / 120\n",
      "2017-10-14 12:02:47.599861 combinations 3 : 100 / 120\n",
      "2017-10-14 12:02:47.722861 combinations 4 : 0 / 210\n",
      "2017-10-14 12:02:48.054400 combinations 4 : 50 / 210\n",
      "2017-10-14 12:02:48.358400 combinations 4 : 100 / 210\n",
      "2017-10-14 12:02:48.741396 combinations 4 : 150 / 210\n",
      "2017-10-14 12:02:49.111866 combinations 4 : 200 / 210\n",
      "2017-10-14 12:02:49.192495 combinations 5 : 0 / 252\n",
      "2017-10-14 12:02:49.630459 combinations 5 : 50 / 252\n",
      "2017-10-14 12:02:50.204478 combinations 5 : 100 / 252\n",
      "2017-10-14 12:02:50.727479 combinations 5 : 150 / 252\n",
      "2017-10-14 12:02:51.372050 combinations 5 : 200 / 252\n",
      "2017-10-14 12:02:52.083941 combinations 5 : 250 / 252\n",
      "2017-10-14 12:02:52.331508 combinations 2 : 0 / 45\n",
      "2017-10-14 12:02:52.662766 combinations 3 : 0 / 120\n",
      "2017-10-14 12:02:53.090224 combinations 3 : 50 / 120\n",
      "2017-10-14 12:02:53.596061 combinations 3 : 100 / 120\n",
      "2017-10-14 12:02:53.821695 combinations 4 : 0 / 210\n",
      "2017-10-14 12:02:54.430290 combinations 4 : 50 / 210\n",
      "2017-10-14 12:02:55.128042 combinations 4 : 100 / 210\n",
      "2017-10-14 12:02:55.911171 combinations 4 : 150 / 210\n",
      "2017-10-14 12:02:56.805210 combinations 4 : 200 / 210\n",
      "2017-10-14 12:02:56.986173 combinations 5 : 0 / 252\n",
      "2017-10-14 12:02:58.135172 combinations 5 : 50 / 252\n",
      "2017-10-14 12:02:59.749209 combinations 5 : 100 / 252\n",
      "2017-10-14 12:03:01.334175 combinations 5 : 150 / 252\n",
      "2017-10-14 12:03:03.045176 combinations 5 : 200 / 252\n",
      "2017-10-14 12:03:04.676175 combinations 5 : 250 / 252\n",
      "2017-10-14 12:03:05.341174 combinations 2 : 0 / 45\n",
      "2017-10-14 12:03:07.179429 combinations 3 : 0 / 120\n",
      "2017-10-14 12:03:09.060390 combinations 3 : 50 / 120\n",
      "2017-10-14 12:03:11.189388 combinations 3 : 100 / 120\n",
      "2017-10-14 12:03:12.087424 combinations 4 : 0 / 210\n",
      "2017-10-14 12:03:14.558390 combinations 4 : 50 / 210\n",
      "2017-10-14 12:03:17.689999 combinations 4 : 100 / 210\n",
      "2017-10-14 12:03:21.142003 combinations 4 : 150 / 210\n",
      "2017-10-14 12:03:24.451037 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.6020376659462797\n",
      "3 0 Train Accuracy: 0.843123036016\n",
      "3 0 Test Accuracy: 0.839738941262\n",
      "2017-10-14 12:03:32.397040 combinations 2 : 0 / 45\n",
      "2017-10-14 12:03:33.791040 combinations 3 : 0 / 120\n",
      "2017-10-14 12:03:35.594003 combinations 3 : 50 / 120\n",
      "2017-10-14 12:03:37.686006 combinations 3 : 100 / 120\n",
      "2017-10-14 12:03:38.599041 combinations 4 : 0 / 210\n",
      "2017-10-14 12:03:41.667047 combinations 4 : 50 / 210\n",
      "2017-10-14 12:03:44.625002 combinations 4 : 100 / 210\n",
      "2017-10-14 12:03:50.315009 combinations 4 : 150 / 210\n",
      "2017-10-14 12:03:54.040041 combinations 4 : 200 / 210\n",
      "2017-10-14 12:03:55.795004 combinations 2 : 0 / 45\n",
      "2017-10-14 12:03:59.129005 combinations 3 : 0 / 120\n",
      "2017-10-14 12:04:03.414043 combinations 3 : 50 / 120\n",
      "2017-10-14 12:04:08.739615 combinations 3 : 100 / 120\n",
      "2017-10-14 12:04:11.532069 combinations 4 : 0 / 210\n",
      "2017-10-14 12:04:17.426281 combinations 4 : 50 / 210\n",
      "2017-10-14 12:04:24.526035 combinations 4 : 100 / 210\n",
      "2017-10-14 12:04:32.316983 combinations 4 : 150 / 210\n",
      "2017-10-14 12:04:40.680986 combinations 4 : 200 / 210\n",
      "2017-10-14 12:04:42.266985 combinations 2 : 0 / 45\n",
      "2017-10-14 12:04:42.481985 combinations 3 : 0 / 120\n",
      "2017-10-14 12:04:42.722022 combinations 3 : 50 / 120\n",
      "2017-10-14 12:04:42.957986 combinations 3 : 100 / 120\n",
      "2017-10-14 12:04:43.106985 combinations 4 : 0 / 210\n",
      "2017-10-14 12:04:43.419987 combinations 4 : 50 / 210\n",
      "2017-10-14 12:04:43.764041 combinations 4 : 100 / 210\n",
      "2017-10-14 12:04:44.123024 combinations 4 : 150 / 210\n",
      "2017-10-14 12:04:44.485026 combinations 4 : 200 / 210\n",
      "\t Predicted -1 but was 1 : 0.9857142857142858\n",
      "3 1 Train Accuracy: 0.960169491525\n",
      "3 1 Test Accuracy: 0.91186440678\n",
      "2017-10-14 12:04:45.997986 combinations 2 : 0 / 45\n",
      "2017-10-14 12:04:46.184992 combinations 3 : 0 / 120\n",
      "2017-10-14 12:04:46.392023 combinations 3 : 50 / 120\n",
      "2017-10-14 12:04:46.645038 combinations 3 : 100 / 120\n",
      "2017-10-14 12:04:46.784026 combinations 4 : 0 / 210\n",
      "2017-10-14 12:04:47.079992 combinations 4 : 50 / 210\n",
      "2017-10-14 12:04:47.418046 combinations 4 : 100 / 210\n",
      "2017-10-14 12:04:47.773993 combinations 4 : 150 / 210\n",
      "2017-10-14 12:04:48.124053 combinations 4 : 200 / 210\n",
      "2017-10-14 12:04:48.438984 combinations 2 : 0 / 45\n",
      "2017-10-14 12:04:48.873990 combinations 3 : 0 / 120\n",
      "2017-10-14 12:04:49.458992 combinations 3 : 50 / 120\n",
      "2017-10-14 12:04:50.090990 combinations 3 : 100 / 120\n",
      "2017-10-14 12:04:50.431987 combinations 4 : 0 / 210\n",
      "2017-10-14 12:04:50.997986 combinations 4 : 50 / 210\n",
      "2017-10-14 12:04:51.666023 combinations 4 : 100 / 210\n",
      "2017-10-14 12:04:52.423986 combinations 4 : 150 / 210\n",
      "2017-10-14 12:04:53.167022 combinations 4 : 200 / 210\n",
      "Count: 250000\n",
      "Train Accuracy: 0.841689055718\n",
      "Test Accuracy: 0.835713161504\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "accuracy_test = 0\n",
    "\n",
    "submission_ids = []\n",
    "submission_y = []\n",
    "\n",
    "result_y = []\n",
    "result_ids = []\n",
    "\n",
    "for numjet in range(0, 4):\n",
    "    for index in range(0, 2):\n",
    "        x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, numjet, index)\n",
    "        \n",
    "        w, predict_threshold, accuracy_train_k, accuracy_test_k = build_best_model(x_, y_, numjet, index)\n",
    "        \n",
    "        number_of_el = len(y_)\n",
    "\n",
    "        accuracy_train += accuracy_train_k * number_of_el\n",
    "        accuracy_test += accuracy_test_k * number_of_el\n",
    "        \n",
    "        print(numjet, index, \"Train Accuracy: \" + str(accuracy_train_k))\n",
    "        print(numjet, index, \"Test Accuracy: \" + str(accuracy_test_k))\n",
    "        \n",
    "        \n",
    "        count += number_of_el\n",
    "  \n",
    "        # Predict local\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x2 = jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids2 = jet_num_ids_dict[numjet][removed_col_key]\n",
    "\n",
    "        sub_x2 = build_features(sub_x2, numjet, index)\n",
    "        pred_y2 = predict_labels(w, sub_x2, predict_threshold)\n",
    "        \n",
    "        for sub_index, sub_id in enumerate(sub_ids2):\n",
    "            result_ids.append(sub_id)\n",
    "            result_y.append(pred_y2[sub_index])\n",
    "        \n",
    "        \n",
    "        # Predict submission\n",
    "        removed_col_key = list(jet_num_x_dict[numjet])[index]\n",
    "        sub_x = sub_jet_num_x_dict[numjet][removed_col_key]\n",
    "        sub_ids = sub_jet_num_ids_dict[numjet][removed_col_key]\n",
    "        \n",
    "        sub_x = build_features(sub_x, numjet, index)\n",
    "        pred_y = predict_labels(w, sub_x, predict_threshold)\n",
    "        for sub_index, sub_id in enumerate(sub_ids):\n",
    "            submission_ids.append(sub_id)\n",
    "            submission_y.append(pred_y[sub_index])\n",
    "        \n",
    "print(\"Count:\", count)\n",
    "print(\"Train Accuracy: \" + str(accuracy_train / count))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69982, 22)\n",
      "2017-10-13 17:20:28.883211 combinations 2 : 0 / 45\n",
      "2017-10-13 17:20:34.544212 combinations 3 : 0 / 120\n",
      "2017-10-13 17:20:41.614212 combinations 3 : 50 / 120\n",
      "2017-10-13 17:20:49.442215 combinations 3 : 100 / 120\n",
      "2017-10-13 17:20:52.798175 combinations 4 : 0 / 210\n",
      "2017-10-13 17:21:03.184176 combinations 4 : 50 / 210\n",
      "2017-10-13 17:21:13.755102 combinations 4 : 100 / 210\n",
      "2017-10-13 17:21:24.333098 combinations 4 : 150 / 210\n",
      "2017-10-13 17:21:35.849104 combinations 4 : 200 / 210\n",
      "Train Accuracy: 0.807784366962\n",
      "Test Accuracy: 0.800943126608\n"
     ]
    }
   ],
   "source": [
    "def build_polynomial2(x, max_degree):\n",
    "    polynomial_x = x\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.tanh(x)), axis=1)\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.log(np.abs(x))), axis=1)\n",
    "    polynomial_x = np.concatenate((polynomial_x, np.sqrt(np.abs(x))), axis=1)\n",
    "\n",
    "    for degree in range(2, max_degree + 1):\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(x, degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.tanh(x), degree)), axis=1)\n",
    "        polynomial_x = np.concatenate((polynomial_x, np.power(np.log(np.abs(x)), degree)), axis=1)\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "\n",
    "\n",
    "def build_features(x):\n",
    "    polynomial_x = normalize(x)\n",
    "    polynomial_x = build_polynomial2(polynomial_x, 5)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "    polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "\n",
    "\n",
    "    return polynomial_x\n",
    "\n",
    "x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, 1, 0)\n",
    "print(x_.shape)\n",
    "polynomial_x = build_features(x_)\n",
    "lambda_ = 0.00007055\n",
    "accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, 5, lambda_)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: \" + str(accuracy_train_k))\n",
    "print(\"Test Accuracy: \" + str(accuracy_test_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-14 11:42:24.849950 combinations 2 : 0 / 45\n",
      "2017-10-14 11:42:25.350954 combinations 3 : 0 / 120\n",
      "2017-10-14 11:42:25.990949 combinations 3 : 50 / 120\n",
      "2017-10-14 11:42:26.665952 combinations 3 : 100 / 120\n",
      "2017-10-14 11:42:26.984957 combinations 4 : 0 / 210\n",
      "2017-10-14 11:42:27.969952 combinations 4 : 50 / 210\n",
      "2017-10-14 11:42:29.037949 combinations 4 : 100 / 210\n",
      "2017-10-14 11:42:30.468950 combinations 4 : 150 / 210\n",
      "2017-10-14 11:42:32.139958 combinations 4 : 200 / 210\n",
      "2017-10-14 11:42:32.659123 combinations 5 : 0 / 252\n",
      "2017-10-14 11:42:34.798669 combinations 5 : 50 / 252\n",
      "2017-10-14 11:42:36.486961 combinations 5 : 100 / 252\n",
      "2017-10-14 11:42:38.190957 combinations 5 : 150 / 252\n",
      "2017-10-14 11:42:39.762306 combinations 5 : 200 / 252\n",
      "2017-10-14 11:42:41.536812 combinations 5 : 250 / 252\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "x_, y_, ids_ = get_data_numjet(jet_num_x_dict, jet_num_y_dict, jet_num_ids_dict, 1, 1)\n",
    "\n",
    "polynomial_x = normalize(x_)\n",
    "polynomial_x = build_polynomial(polynomial_x, 3)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 2, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 3, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 4, 10)\n",
    "polynomial_x = build_combinations_lvl(polynomial_x, 5, 10)\n",
    "\n",
    "predict_threshold = -0.00\n",
    "\n",
    "lambdas = np.logspace(-5, 0, 30)\n",
    "# 0.204335971786 0.919312169312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas: 1e-05 Train: 0.939484126984  Test: 0.911375661376\n",
      "Lambdas: 1.48735210729e-05 Train: 0.939484126984  Test: 0.911375661376\n",
      "Lambdas: 2.21221629107e-05 Train: 0.939484126984  Test: 0.912037037037\n",
      "Lambdas: 3.29034456231e-05 Train: 0.939649470899  Test: 0.912037037037\n",
      "Lambdas: 4.89390091848e-05 Train: 0.939649470899  Test: 0.912037037037\n",
      "Lambdas: 7.27895384398e-05 Train: 0.939649470899  Test: 0.912698412698\n",
      "Lambdas: 0.000108263673387 Train: 0.939649470899  Test: 0.912698412698\n",
      "Lambdas: 0.000161026202756 Train: 0.939318783069  Test: 0.91335978836\n",
      "Lambdas: 0.000239502661999 Train: 0.938822751323  Test: 0.91335978836\n",
      "Lambdas: 0.000356224789026 Train: 0.938492063492  Test: 0.91335978836\n",
      "Lambdas: 0.000529831690628 Train: 0.938326719577  Test: 0.915343915344\n",
      "Lambdas: 0.000788046281567 Train: 0.937996031746  Test: 0.914682539683\n",
      "Lambdas: 0.00117210229753 Train: 0.9375  Test: 0.915343915344\n",
      "Lambdas: 0.0017433288222 Train: 0.937334656085  Test: 0.916005291005\n",
      "Lambdas: 0.0025929437974 Train: 0.936342592593  Test: 0.916666666667\n",
      "Lambdas: 0.00385662042116 Train: 0.936011904762  Test: 0.915343915344\n",
      "Lambdas: 0.00573615251045 Train: 0.935846560847  Test: 0.915343915344\n",
      "Lambdas: 0.00853167852417 Train: 0.935515873016  Test: 0.916666666667\n",
      "Lambdas: 0.0126896100317 Train: 0.934523809524  Test: 0.916005291005\n",
      "Lambdas: 0.0188739182214 Train: 0.933862433862  Test: 0.916666666667\n",
      "Lambdas: 0.0280721620394 Train: 0.933697089947  Test: 0.917989417989\n",
      "Lambdas: 0.0417531893656 Train: 0.933697089947  Test: 0.916005291005\n",
      "Lambdas: 0.0621016941892 Train: 0.933531746032  Test: 0.917328042328\n",
      "Lambdas: 0.0923670857187 Train: 0.932208994709  Test: 0.918650793651\n",
      "Lambdas: 0.137382379588 Train: 0.930555555556  Test: 0.920634920635\n",
      "Lambdas: 0.204335971786 Train: 0.928736772487  Test: 0.920634920635\n",
      "Lambdas: 0.303919538231 Train: 0.927579365079  Test: 0.919973544974\n",
      "Lambdas: 0.452035365636 Train: 0.925595238095  Test: 0.918650793651\n",
      "Lambdas: 0.67233575365 Train: 0.925264550265  Test: 0.917989417989\n",
      "Lambdas: 1.0 Train: 0.922453703704  Test: 0.916005291005\n",
      "\t Predicted -1 but was 1 : 0.9713740458015268\n",
      "BEST: 0.137382379588 0.920634920635\n"
     ]
    }
   ],
   "source": [
    "# Here to test the accuracy of one specific classifier\n",
    "# Find best lambdas\n",
    "\n",
    "best_accuracy = 0\n",
    "best_lambda = 0\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_lambda = lambda_\n",
    "    print(\"Lambdas:\", lambda_, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_lambda, best_accuracy)\n",
    "lambda_ = best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh: 0.0 Train: 0.930555555556  Test: 0.920634920635\n",
      "Thresh: -0.0040404040404 Train: 0.931051587302  Test: 0.920634920635\n",
      "Thresh: -0.00808080808081 Train: 0.931051587302  Test: 0.920634920635\n",
      "Thresh: -0.0121212121212 Train: 0.930886243386  Test: 0.920634920635\n",
      "Thresh: -0.0161616161616 Train: 0.930886243386  Test: 0.920634920635\n",
      "Thresh: -0.020202020202 Train: 0.930720899471  Test: 0.920634920635\n",
      "Thresh: -0.0242424242424 Train: 0.931051587302  Test: 0.919973544974\n",
      "Thresh: -0.0282828282828 Train: 0.931051587302  Test: 0.919312169312\n",
      "Thresh: -0.0323232323232 Train: 0.931216931217  Test: 0.919312169312\n",
      "Thresh: -0.0363636363636 Train: 0.931216931217  Test: 0.919973544974\n",
      "Thresh: -0.040404040404 Train: 0.931051587302  Test: 0.919973544974\n",
      "Thresh: -0.0444444444444 Train: 0.931216931217  Test: 0.919973544974\n",
      "Thresh: -0.0484848484848 Train: 0.931216931217  Test: 0.919973544974\n",
      "Thresh: -0.0525252525253 Train: 0.931547619048  Test: 0.919973544974\n",
      "Thresh: -0.0565656565657 Train: 0.931547619048  Test: 0.920634920635\n",
      "Thresh: -0.0606060606061 Train: 0.931382275132  Test: 0.920634920635\n",
      "Thresh: -0.0646464646465 Train: 0.931382275132  Test: 0.921957671958\n",
      "Thresh: -0.0686868686869 Train: 0.931382275132  Test: 0.920634920635\n",
      "Thresh: -0.0727272727273 Train: 0.931382275132  Test: 0.920634920635\n",
      "Thresh: -0.0767676767677 Train: 0.931547619048  Test: 0.920634920635\n",
      "Thresh: -0.0808080808081 Train: 0.931547619048  Test: 0.920634920635\n",
      "Thresh: -0.0848484848485 Train: 0.931547619048  Test: 0.920634920635\n",
      "Thresh: -0.0888888888889 Train: 0.931712962963  Test: 0.920634920635\n",
      "Thresh: -0.0929292929293 Train: 0.931878306878  Test: 0.920634920635\n",
      "Thresh: -0.0969696969697 Train: 0.931878306878  Test: 0.920634920635\n",
      "Thresh: -0.10101010101 Train: 0.932374338624  Test: 0.920634920635\n",
      "Thresh: -0.105050505051 Train: 0.932374338624  Test: 0.919973544974\n",
      "Thresh: -0.109090909091 Train: 0.932374338624  Test: 0.919973544974\n",
      "Thresh: -0.113131313131 Train: 0.932208994709  Test: 0.918650793651\n",
      "Thresh: -0.117171717172 Train: 0.931878306878  Test: 0.918650793651\n",
      "Thresh: -0.121212121212 Train: 0.932043650794  Test: 0.917989417989\n",
      "Thresh: -0.125252525253 Train: 0.931878306878  Test: 0.917989417989\n",
      "Thresh: -0.129292929293 Train: 0.931878306878  Test: 0.917989417989\n",
      "Thresh: -0.133333333333 Train: 0.932043650794  Test: 0.917328042328\n",
      "Thresh: -0.137373737374 Train: 0.931878306878  Test: 0.917328042328\n",
      "Thresh: -0.141414141414 Train: 0.932043650794  Test: 0.917328042328\n",
      "Thresh: -0.145454545455 Train: 0.931878306878  Test: 0.917328042328\n",
      "Thresh: -0.149494949495 Train: 0.932208994709  Test: 0.917328042328\n",
      "Thresh: -0.153535353535 Train: 0.932208994709  Test: 0.917328042328\n",
      "Thresh: -0.157575757576 Train: 0.931712962963  Test: 0.917328042328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-d6f56274c48d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredict_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0maccuracy_train_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_test_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_fold_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolynomial_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccuracy_test_k\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-119-5069343d0308>\u001b[0m in \u001b[0;36mk_fold_cross_validation\u001b[1;34m(y, x, k, lambda_, predict_threshold)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# ridge regression:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# calculate the loss for train and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Coac\\Documents\\PersonalProjects\\epfl\\epfl-ml-projects\\epfl-ml-project1\\gradient_descent.py\u001b[0m in \u001b[0;36mridge_regression\u001b[1;34m(y, tx, lambda_)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mgram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mlambda_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshs = np.linspace(0, -0.4, num=100)\n",
    "best_accuracy = 0\n",
    "best_thresh = 0\n",
    "for thresh in threshs:\n",
    "    predict_threshold = thresh\n",
    "    \n",
    "    accuracy_train_k, accuracy_test_k = k_fold_cross_validation(y_, polynomial_x, k, lambda_, predict_threshold)\n",
    "\n",
    "    if accuracy_test_k > best_accuracy:\n",
    "        best_accuracy = accuracy_test_k\n",
    "        best_thresh = thresh\n",
    "    print(\"Thresh:\", thresh, \"Train:\", accuracy_train_k, \" Test:\", accuracy_test_k)\n",
    "\n",
    "w, loss = ridge_regression(y_, polynomial_x, best_lambda)\n",
    "\n",
    "print(\"\\t Predicted -1 but was 1 :\", get_false(polynomial_x, y_, w, predict_threshold))\n",
    "\n",
    "print(\"BEST:\", best_thresh, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
