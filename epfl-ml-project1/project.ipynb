{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from helpers import *\n",
    "from costs import *\n",
    "from gradient_descent import *\n",
    "from stochastic_gradient_descent import *\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x, ids = load_csv_data(data_path=\"datas/train.csv\", sub_sample=False)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7406783.4156743856"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(x.shape[1])\n",
    "compute_loss(y, x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = compute_gradient(y, x, w)\n",
    "gradient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/4): loss=4668689.851519833\t\t0.311176\n",
      "Gradient Descent(1/4): loss=2433848.286550006\t\t0.628188\n",
      "Gradient Descent(2/4): loss=1271670.8726504748\t\t0.311368\n",
      "Gradient Descent(3/4): loss=666797.10350315\t\t0.619588\n",
      "Gradient Descent(4/4): loss=351603.1677181949\t\t0.313124\n"
     ]
    }
   ],
   "source": [
    "w_init = np.random.rand(x.shape[1])\n",
    "w, loss = least_squares_GD(y, x, w_init, max_iters=5, gamma=0.0000003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (0/99): loss=4639319.38649347\t\t0.628856\n",
      "SGD (1/99): loss=4522568.978539087\t\t0.63036\n",
      "SGD (2/99): loss=4565628.518960947\t\t0.333224\n",
      "SGD (3/99): loss=4495401.0464098\t\t0.329932\n",
      "SGD (4/99): loss=3419612.0841454435\t\t0.640032\n",
      "SGD (5/99): loss=3350054.2989346287\t\t0.640036\n",
      "SGD (6/99): loss=2333074.6159276688\t\t0.328132\n",
      "SGD (7/99): loss=2801067.350246347\t\t0.640028\n",
      "SGD (8/99): loss=241647.9951472858\t\t0.551148\n",
      "SGD (9/99): loss=290346.30258515314\t\t0.428032\n",
      "SGD (10/99): loss=246515.03654284708\t\t0.555736\n",
      "SGD (11/99): loss=717169.5130690602\t\t0.631372\n",
      "SGD (12/99): loss=422668.5802511151\t\t0.567204\n",
      "SGD (13/99): loss=477015.7328742842\t\t0.61252\n",
      "SGD (14/99): loss=645035.1805172437\t\t0.33028\n",
      "SGD (15/99): loss=623668.3249523262\t\t0.358948\n",
      "SGD (16/99): loss=605362.719569157\t\t0.396024\n",
      "SGD (17/99): loss=611464.1964490984\t\t0.617692\n",
      "SGD (18/99): loss=4044959.0946316104\t\t0.328384\n",
      "SGD (19/99): loss=3196531.713614161\t\t0.639732\n",
      "SGD (20/99): loss=3894921.010989881\t\t0.32326\n",
      "SGD (21/99): loss=628510.296221939\t\t0.637792\n",
      "SGD (22/99): loss=1031433.7192748943\t\t0.336032\n",
      "SGD (23/99): loss=1355686.9661315666\t\t0.64002\n",
      "SGD (24/99): loss=301484.765929917\t\t0.326348\n",
      "SGD (25/99): loss=292140.093519382\t\t0.325644\n",
      "SGD (26/99): loss=386319.9367732097\t\t0.630136\n",
      "SGD (27/99): loss=1281715.999144496\t\t0.323884\n",
      "SGD (28/99): loss=46485.50493743373\t\t0.514988\n",
      "SGD (29/99): loss=45756.55427136053\t\t0.51414\n",
      "SGD (30/99): loss=115594.0341740678\t\t0.3517\n",
      "SGD (31/99): loss=49261.42010830751\t\t0.514644\n",
      "SGD (32/99): loss=76390.88554995896\t\t0.352776\n",
      "SGD (33/99): loss=188799.98149013933\t\t0.626632\n",
      "SGD (34/99): loss=297898.6637073477\t\t0.320684\n",
      "SGD (35/99): loss=52739.0398401568\t\t0.615356\n",
      "SGD (36/99): loss=13165.714435539925\t\t0.42726\n",
      "SGD (37/99): loss=29869.407960239045\t\t0.611816\n",
      "SGD (38/99): loss=9986.706556344874\t\t0.481784\n",
      "SGD (39/99): loss=10007.803725556932\t\t0.480996\n",
      "SGD (40/99): loss=18988.586213068502\t\t0.35134\n",
      "SGD (41/99): loss=47522.11155903766\t\t0.61452\n",
      "SGD (42/99): loss=46428.5340015391\t\t0.613312\n",
      "SGD (43/99): loss=43747.30014069685\t\t0.611516\n",
      "SGD (44/99): loss=113805.22729999002\t\t0.312696\n",
      "SGD (45/99): loss=115619.67759041753\t\t0.313168\n",
      "SGD (46/99): loss=116774.08767910617\t\t0.31356\n",
      "SGD (47/99): loss=16145.465696189049\t\t0.396932\n",
      "SGD (48/99): loss=16277.772367516949\t\t0.397036\n",
      "SGD (49/99): loss=51742.2027920588\t\t0.59658\n",
      "SGD (50/99): loss=52251.65060141871\t\t0.596816\n",
      "SGD (51/99): loss=51630.630006105384\t\t0.596464\n",
      "SGD (52/99): loss=16320.05100613734\t\t0.396796\n",
      "SGD (53/99): loss=16543.118696314676\t\t0.397968\n",
      "SGD (54/99): loss=60333.82076955532\t\t0.596152\n",
      "SGD (55/99): loss=16921.30205499754\t\t0.397732\n",
      "SGD (56/99): loss=56016.739985354005\t\t0.596296\n",
      "SGD (57/99): loss=31599.702762667945\t\t0.360408\n",
      "SGD (58/99): loss=35075.50337001946\t\t0.347388\n",
      "SGD (59/99): loss=29026.667709678954\t\t0.37352\n",
      "SGD (60/99): loss=78367.1681200787\t\t0.596384\n",
      "SGD (61/99): loss=82125.8942154482\t\t0.597448\n",
      "SGD (62/99): loss=40966.5424233841\t\t0.32644\n",
      "SGD (63/99): loss=41160.59211530835\t\t0.3262\n",
      "SGD (64/99): loss=98833.92204155381\t\t0.594144\n",
      "SGD (65/99): loss=45079.2892286845\t\t0.307928\n",
      "SGD (66/99): loss=52951.491476585164\t\t0.59464\n",
      "SGD (67/99): loss=54739.428182474396\t\t0.30762\n",
      "SGD (68/99): loss=8378.532195330587\t\t0.350596\n",
      "SGD (69/99): loss=8873.584072362555\t\t0.353016\n",
      "SGD (70/99): loss=61680.36291493063\t\t0.592564\n",
      "SGD (71/99): loss=26128.911574535392\t\t0.307924\n",
      "SGD (72/99): loss=19805.013458116766\t\t0.58862\n",
      "SGD (73/99): loss=11147.095610870287\t\t0.55992\n",
      "SGD (74/99): loss=8864.590542719567\t\t0.533888\n",
      "SGD (75/99): loss=9241.57555968628\t\t0.54286\n",
      "SGD (76/99): loss=5997.044016793974\t\t0.506852\n",
      "SGD (77/99): loss=14480.254479284878\t\t0.31046\n",
      "SGD (78/99): loss=14623.745997294365\t\t0.310844\n",
      "SGD (79/99): loss=5476.888087409103\t\t0.545632\n",
      "SGD (80/99): loss=14632.280520780132\t\t0.311448\n",
      "SGD (81/99): loss=14787.732424805443\t\t0.312608\n",
      "SGD (82/99): loss=14891.38678771765\t\t0.313168\n",
      "SGD (83/99): loss=6003.637819955696\t\t0.550944\n",
      "SGD (84/99): loss=4837.7047439397065\t\t0.529208\n",
      "SGD (85/99): loss=4855.420629197475\t\t0.52944\n",
      "SGD (86/99): loss=26947.95700364\t\t0.3138\n",
      "SGD (87/99): loss=27910.604320632003\t\t0.31546\n",
      "SGD (88/99): loss=16025.424743237558\t\t0.591156\n",
      "SGD (89/99): loss=8104.567043101359\t\t0.31356\n",
      "SGD (90/99): loss=3578.751837562783\t\t0.525664\n",
      "SGD (91/99): loss=3538.148532543399\t\t0.525952\n",
      "SGD (92/99): loss=5019.57409814215\t\t0.317576\n",
      "SGD (93/99): loss=4925.672406908467\t\t0.3183\n",
      "SGD (94/99): loss=3959.852116897215\t\t0.549996\n",
      "SGD (95/99): loss=3902.1223159733154\t\t0.547488\n",
      "SGD (96/99): loss=3186.0164825865836\t\t0.483528\n",
      "SGD (97/99): loss=3278.0426505683686\t\t0.5136\n",
      "SGD (98/99): loss=3290.2918870386975\t\t0.510992\n",
      "SGD (99/99): loss=2976.635034160663\t\t0.441316\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares_SGD(y, x, w_init, 100, gamma=0.0000002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.441316"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(x, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test, ids_test = load_csv_data(data_path=\"datas/test.csv\", sub_sample=False)\n",
    "pred_y = predict_labels(w, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, pred_y, \"datas/submission.csv\")\n",
    "print('Done !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
